2022-07-23 23:07:20 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-23 23:07:20 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(3300, 1024, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=1024, out_features=6399, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=6399, out_features=3300, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-23 23:07:20 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(0,), #param: 41.04M
2022-07-23 23:07:22 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:11:04 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-23 23:11:04 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(3300, 1024, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=1024, out_features=6399, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=6399, out_features=3300, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-23 23:11:04 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(0,), #param: 41.04M
2022-07-23 23:11:06 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:11:17 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +55.10)...
2022-07-23 23:11:26 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 55.93,52.41,56.37,52.48,56.62,54.18,52.10,55.81,53.77,53.94,54.61,60.67,53.41,54.44,53.12,57.79,53.68,51.70,53.63,53.78,56.74,58.19,54.09,56.80,50.76,58.62,56.06,54.00,57.50,55.72,54.30,54.90,55.65,57.28,58.00,50.14,58.09,56.79,55.63,58.84,54.62,53.35,55.76,53.99,55.82,54.30,55.91,53.22,57.13,52.15,54.99,54.71,50.36,54.81,56.39,56.51,53.54,54.90,55.42,54.21,58.64,55.63,60.30,52.81,54.24,54.94,54.89,51.18,54.93,52.95,52.69,58.56,60.07,53.79,50.67,57.01,52.41,55.85,51.97,52.78,54.42,55.91,55.58,59.72,60.18,56.98,54.44,55.21,54.45
2022-07-23 23:11:26 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 55.0989
2022-07-23 23:11:26 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-23 23:13:13 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-23 23:13:13 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(3300, 1024, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=1024, out_features=6399, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=6399, out_features=3300, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-23 23:13:13 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(6,), #param: 41.04M
2022-07-23 23:13:16 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:13:23 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +64.26)...
2022-07-23 23:13:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 61.87,62.56,63.83,63.92,66.16,63.22,63.67,61.57,66.63,64.62,60.95,67.35,61.37,64.75,64.91,67.19,67.41,62.72,64.88,62.91,66.44,70.54,66.85,61.16,60.03,63.80,64.03,66.58,64.73,59.56,64.13,64.81,63.55,65.52,64.35,64.65,65.79,65.00,70.31,63.11,63.63,63.14,65.33,65.24,61.35,61.32,62.20,66.68,65.76,61.08,63.18,61.86,64.44,62.90,62.46,62.35,64.19,67.15,62.52,59.93,70.06,60.60,65.07,64.24,62.75,60.79,65.27,64.07,62.17,61.55,59.38,66.42,66.97,68.42,66.95,63.61,63.95,59.47,66.38,60.39,61.60,65.27,65.34,67.25,62.00,60.14,63.58,63.55,62.72
2022-07-23 23:13:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 63.9791
2022-07-23 23:13:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-23 23:13:51 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +44.07)...
2022-07-23 23:14:07 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.70)...
2022-07-23 23:14:23 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +43.75)...
2022-07-23 23:14:40 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +43.72)...
2022-07-23 23:14:57 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +42.94)...
2022-07-23 23:15:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +42.86)...
2022-07-23 23:15:30 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +43.42)...
2022-07-23 23:15:46 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +43.65)...
2022-07-23 23:16:01 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +42.80)...
2022-07-23 23:16:16 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +42.75)...
2022-07-23 23:16:32 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +42.67)...
2022-07-23 23:16:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:16:43 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +42.62)...
2022-07-23 23:16:48 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 39.06,43.37,38.77,37.72,41.58,44.63,43.38,42.00,38.29,44.11,40.76,42.87,44.55,46.16,46.01,46.41,37.31,44.27,40.67,45.76,43.12,42.83,41.89,43.44,42.60,44.79,41.98,41.13,44.17,43.92,42.65,44.22,44.10,40.24,39.55,46.85,39.11,41.27,39.18,42.63,42.25,42.02,46.00,42.29,45.02,46.21,41.43,41.97,43.65,43.05,42.81,38.77,38.94,43.16,42.42,39.86,42.89,41.90,45.40,39.16,45.27,41.81,42.11,42.77,43.23,43.37,38.30,43.16,46.23,40.87,47.72,41.86,45.48,39.97,41.94,44.57,40.29,43.25,47.09,45.95,41.94,43.81,42.01,45.26,46.55,42.98,43.61,40.78,46.47
2022-07-23 23:16:54 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  1: train = +43.2988(3.11m/561) | dev = +42.7556(0.21m/89) 
2022-07-23 23:17:00 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-23 23:17:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +42.12)...
2022-07-23 23:17:30 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.05)...
2022-07-23 23:17:46 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +42.85)...
2022-07-23 23:18:01 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +43.27)...
2022-07-23 23:18:17 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +42.49)...
2022-07-23 23:18:32 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +43.15)...
2022-07-23 23:18:47 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +42.83)...
2022-07-23 23:19:03 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +42.60)...
2022-07-23 23:19:18 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +42.90)...
2022-07-23 23:19:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +42.80)...
2022-07-23 23:19:49 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +42.95)...
2022-07-23 23:19:52 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:20:00 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.29)...
2022-07-23 23:20:05 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 48.52,40.63,42.05,42.29,45.05,48.28,44.37,47.03,42.39,41.74,38.52,39.88,41.32,40.12,47.58,46.25,44.88,43.60,41.30,41.18,42.84,38.89,43.51,40.07,42.58,42.40,43.61,43.22,47.38,44.95,46.89,47.93,42.60,38.32,45.15,48.37,40.42,43.27,43.92,43.93,43.33,44.42,40.82,44.34,38.52,44.89,42.78,42.12,42.93,43.33,44.18,48.69,41.55,42.00,43.62,44.71,43.52,43.20,43.20,41.73,42.12,44.36,41.98,44.10,40.44,43.71,41.61,43.10,42.84,43.36,43.48,43.40,43.75,41.45,46.60,45.10,41.71,41.20,46.91,42.63,41.45,41.48,39.45,48.75,46.43,44.19,49.73,43.43,46.42
2022-07-23 23:20:05 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  2: train = +42.8291(2.87m/561) | dev = +43.4418(0.21m/89) | no impr, best = 42.7556
2022-07-23 23:20:11 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-23 23:20:37 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +42.85)...
2022-07-23 23:20:53 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.00)...
2022-07-23 23:21:08 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +42.59)...
2022-07-23 23:21:23 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +42.73)...
2022-07-23 23:21:38 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +43.47)...
2022-07-23 23:21:54 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +42.63)...
2022-07-23 23:22:09 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +42.81)...
2022-07-23 23:22:25 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +43.93)...
2022-07-23 23:22:41 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +44.62)...
2022-07-23 23:22:56 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +43.62)...
2022-07-23 23:23:12 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +43.18)...
2022-07-23 23:23:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:23:23 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +44.47)...
2022-07-23 23:23:28 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 42.53,46.66,49.37,46.48,43.80,44.58,40.93,44.24,41.42,45.63,42.98,45.22,46.37,44.12,40.68,47.37,42.53,48.25,51.25,42.86,44.15,46.56,48.05,45.58,43.33,44.19,42.96,40.80,43.58,45.99,43.74,49.49,44.80,41.91,45.34,43.44,42.06,44.81,41.06,40.89,44.52,44.73,48.18,41.94,46.58,44.51,40.47,48.13,42.02,42.20,42.79,48.08,40.75,41.34,43.92,46.10,41.14,44.58,45.26,45.14,47.58,42.86,41.61,43.83,43.06,42.10,40.99,45.74,44.61,44.12,47.79,43.26,44.47,44.20,44.19,42.29,42.57,45.96,43.19,43.21,45.41,42.82,38.16,44.51,39.57,45.47,40.07,42.43,48.62
2022-07-23 23:23:28 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  3: train = +43.1924(3.06m/561) | dev = +44.1244(0.22m/89) | no impr, best = 42.7556
2022-07-23 23:23:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-23 23:24:32 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.23)...
2022-07-23 23:24:48 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +42.81)...
2022-07-23 23:25:03 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +44.18)...
2022-07-23 23:25:19 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +44.02)...
2022-07-23 23:25:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +43.52)...
2022-07-23 23:25:50 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +42.92)...
2022-07-23 23:26:06 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +42.93)...
2022-07-23 23:26:21 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +44.26)...
2022-07-23 23:26:38 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +44.21)...
2022-07-23 23:26:53 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +44.96)...
2022-07-23 23:27:09 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +44.31)...
2022-07-23 23:27:27 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:27:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +45.09)...
2022-07-23 23:27:40 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 45.15,50.43,46.45,44.56,44.77,47.33,44.56,47.08,41.61,48.29,43.73,46.20,48.00,42.85,41.59,49.59,44.64,47.27,46.62,43.40,45.18,42.91,42.62,44.47,44.66,43.93,45.35,41.68,43.76,42.75,44.99,48.99,48.57,49.36,45.15,43.04,43.00,47.40,43.80,40.99,44.17,45.94,47.40,48.16,41.58,47.05,42.97,45.52,42.22,42.76,47.62,48.50,42.97,46.16,41.29,44.13,48.56,48.29,44.26,48.99,44.46,44.80,46.19,41.57,40.77,41.96,42.68,41.91,47.07,45.97,50.45,44.99,44.63,43.88,42.50,43.81,47.56,45.56,44.87,45.77,43.72,45.21,42.14,44.93,41.32,45.80,42.04,47.02,49.22
2022-07-23 23:27:40 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  4: train = +43.7687(3.86m/561) | dev = +45.0341(0.22m/89) | no impr, best = 42.7556
2022-07-23 23:28:24 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-23 23:33:25 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-23 23:33:25 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(1024, 1024, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=1024, out_features=512, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=6399, out_features=1024, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-23 23:33:25 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(6,), #param: 13.45M
2022-07-23 23:33:28 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:42:21 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-23 23:42:21 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(1024, 1024, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=1024, out_features=6399, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=6399, out_features=1024, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-23 23:42:21 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(6,), #param: 19.49M
2022-07-23 23:42:22 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-23 23:42:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +62.93)...
2022-07-23 23:42:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 64.07,65.71,64.13,60.90,63.12,64.52,67.44,63.46,61.38,65.61,60.26,60.21,64.24,61.35,63.18,60.66,62.36,64.57,65.89,64.03,67.53,63.86,57.63,61.86,61.11,60.91,62.58,60.56,62.19,62.51,63.07,62.71,65.00,62.70,62.53,63.64,64.96,60.66,64.74,62.02,64.41,59.41,59.27,61.79,58.19,61.16,64.58,68.36,62.61,66.77,62.99,63.96,62.16,60.94,61.03,59.60,62.29,67.65,63.45,64.65,59.55,65.91,65.39,60.94,61.55,63.52,62.95,62.78,63.18,61.68,66.03,67.65,65.48,61.40,63.12,60.18,63.59,62.36,60.19,61.35,60.77,60.07,61.53,60.60,62.45,64.42,61.64,63.80,60.64
2022-07-23 23:42:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 62.8070
2022-07-23 23:42:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-23 23:42:48 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +45.41)...
2022-07-23 23:43:03 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.92)...
2022-07-23 23:43:17 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +43.43)...
2022-07-23 23:43:31 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +42.75)...
2022-07-23 23:43:45 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +43.80)...
2022-07-23 23:45:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-23 23:45:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(40,), stride=(20,))
  (gru_net): GRUC(
    (gru): GRU(1024, 1024, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=1024, out_features=6399, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=6399, out_features=1024, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(40,), stride=(20,))
)
2022-07-23 23:45:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(6,), #param: 19.50M
2022-07-23 23:45:42 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:53:41 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 17:53:41 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(40,), stride=(20,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=3199, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(40,), stride=(20,))
)
2022-07-24 17:53:41 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(6,), #param: 3.43M
2022-07-24 17:53:41 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:59:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 17:59:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(40,), stride=(20,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=3199, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Linear(in_features=256, out_features=3199, bias=True)
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(40,), stride=(20,))
)
2022-07-24 17:59:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(6,), #param: 4.25M
2022-07-24 17:59:30 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:59:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +54.62)...
2022-07-24 17:59:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 52.50,54.43,54.63,55.32,55.27,53.99,56.56,54.84,52.22,55.83,54.13,60.05,53.14,53.14,54.09,53.40,53.81,59.06,51.59,55.60,58.12,52.56,51.72,51.69,56.95,57.03,52.29,52.93,56.42,53.74,52.09,55.10,57.07,54.69,53.46,55.98,52.84,52.54,57.80,52.42,53.92,56.93,53.60,57.18,54.48,53.54,58.74,52.99,54.67,54.01,53.98,54.24,52.78,51.43,59.51,57.44,53.64,54.52,60.20,54.47,56.21,53.80,55.88,56.82,60.10,54.40,52.53,57.38,52.70,55.68,58.50,53.83,56.32,55.30,55.69,60.07,54.35,55.15,50.77,55.70,56.05,56.04,54.04,55.99,53.28,50.59,52.22,54.73,56.32
2022-07-24 17:59:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 54.8734
2022-07-24 17:59:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:00:33 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 18:00:33 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(40,), stride=(20,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=3199, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Linear(in_features=256, out_features=3199, bias=True)
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(40,), stride=(20,))
)
2022-07-24 18:00:33 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(4,), #param: 4.25M
2022-07-24 18:00:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:00:36 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +58.77)...
2022-07-24 18:00:38 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 60.33,56.54,62.04,59.76,56.77,56.22,57.71,59.81,59.92,61.51,55.43,61.09,57.30,61.49,58.71,58.90,61.61,61.08,55.77,59.34,59.58,59.63,57.73,58.78,59.86,54.92,58.57,50.96,55.63,60.05,57.77,62.44,64.01,59.96,54.90,56.80,57.17,57.72,55.48,64.66,55.18,58.41,60.64,59.92,63.41,60.52,56.20,57.35,58.98,60.16,56.56,60.76,63.20,58.35,56.99,57.01,58.85,56.70,58.19,54.39,57.11,58.41,56.68,59.88,54.96,62.34,55.05,58.34,58.43,57.29,60.96,61.12,57.29,57.78,58.18,58.35,58.65,56.27,57.25,59.02,60.56,59.94,56.16,55.83,60.01,57.24,58.98,57.74,59.55
2022-07-24 18:00:38 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 58.5289
2022-07-24 18:00:38 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:00:42 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +45.15)...
2022-07-24 18:00:49 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +44.28)...
2022-07-24 18:00:52 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +44.65)...
2022-07-24 18:00:58 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +45.10)...
2022-07-24 18:01:03 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +43.79)...
2022-07-24 18:01:07 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +43.24)...
2022-07-24 18:01:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +43.85)...
2022-07-24 18:01:20 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +44.35)...
2022-07-24 18:01:26 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +44.22)...
2022-07-24 18:01:31 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +44.15)...
2022-07-24 18:01:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +44.33)...
2022-07-24 18:01:36 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:01:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.66)...
2022-07-24 18:01:44 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 43.42,47.58,43.60,44.54,47.88,44.25,42.22,44.92,43.72,39.41,49.06,43.84,46.34,42.50,41.54,42.03,44.56,42.01,40.27,42.26,43.78,42.88,49.78,45.55,42.78,42.55,43.41,42.16,46.38,41.96,40.67,45.42,45.26,42.58,47.05,46.65,43.26,46.76,40.52,41.66,45.87,43.20,44.09,42.70,38.78,41.91,42.56,40.92,43.13,43.02,41.82,42.68,42.20,43.18,46.08,46.57,42.64,42.49,45.70,39.85,43.39,41.21,41.68,44.43,45.26,42.32,42.37,45.99,41.41,40.37,42.39,50.06,42.72,44.29,46.01,44.83,42.75,43.08,40.50,41.82,48.89,45.92,38.82,48.69,44.29,43.81,47.44,42.25,44.53
2022-07-24 18:01:45 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  1: train = +44.2695(0.98m/561) | dev = +43.6843(0.13m/89) 
2022-07-24 18:01:45 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:01:50 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.49)...
2022-07-24 18:01:54 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.56)...
2022-07-24 18:02:00 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +44.29)...
2022-07-24 18:02:05 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +44.09)...
2022-07-24 18:02:09 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +43.19)...
2022-07-24 18:02:12 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +43.37)...
2022-07-24 18:02:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +43.20)...
2022-07-24 18:02:19 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +43.55)...
2022-07-24 18:02:22 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +43.97)...
2022-07-24 18:02:26 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +42.19)...
2022-07-24 18:02:29 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +43.24)...
2022-07-24 18:02:30 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:02:32 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.45)...
2022-07-24 18:02:34 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 46.00,46.47,46.81,44.41,49.07,46.03,40.28,46.61,45.98,42.49,45.50,42.43,46.57,41.82,42.67,39.52,45.78,42.75,40.44,42.71,42.49,40.29,46.74,46.59,44.60,40.72,43.60,40.98,47.97,43.05,43.00,42.68,44.67,41.54,44.98,46.64,43.21,43.88,40.84,43.54,44.79,42.33,44.44,39.90,38.25,42.31,41.86,37.72,41.80,42.60,40.44,43.50,40.29,41.70,46.67,44.84,41.84,40.40,44.17,38.67,41.37,41.66,44.71,43.76,42.28,44.44,45.07,45.65,42.30,41.22,42.86,46.31,44.09,42.84,47.02,43.04,42.57,44.31,39.99,42.27,43.94,42.92,39.75,47.31,45.68,45.22,47.80,43.16,43.23
2022-07-24 18:02:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  2: train = +43.4714(0.74m/561) | dev = +43.3895(0.07m/89) 
2022-07-24 18:02:35 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:02:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +42.63)...
2022-07-24 18:02:44 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.14)...
2022-07-24 18:02:48 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +43.58)...
2022-07-24 18:02:51 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +43.02)...
2022-07-24 18:02:54 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +42.89)...
2022-07-24 18:02:58 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +42.97)...
2022-07-24 18:03:01 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +43.29)...
2022-07-24 18:03:04 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +43.33)...
2022-07-24 18:03:08 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +42.81)...
2022-07-24 18:03:11 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +42.85)...
2022-07-24 18:03:14 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +43.08)...
2022-07-24 18:03:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:03:17 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.12)...
2022-07-24 18:03:18 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 42.38,42.20,43.63,41.84,46.06,47.13,40.80,45.60,46.47,37.81,43.64,40.56,41.88,41.52,41.51,40.04,45.03,38.22,39.60,46.79,41.07,40.13,47.05,42.41,42.10,40.92,43.86,46.01,46.92,44.03,42.97,44.76,46.34,41.57,42.55,47.03,46.20,46.60,43.19,43.29,43.65,43.63,47.45,41.50,42.17,41.27,40.41,38.18,43.95,42.21,43.90,43.44,41.70,40.46,42.88,42.64,42.02,41.97,42.20,40.93,44.01,43.07,46.78,45.49,45.84,44.25,41.37,44.75,41.32,38.00,41.94,50.17,43.29,42.16,49.48,41.92,44.25,43.14,38.99,44.95,43.93,42.65,39.32,49.23,43.28,50.65,43.30,40.12,46.77
2022-07-24 18:03:19 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  3: train = +43.0562(0.67m/561) | dev = +43.2889(0.05m/89) 
2022-07-24 18:03:20 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:03:23 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +42.57)...
2022-07-24 18:03:27 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.30)...
2022-07-24 18:03:30 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +43.19)...
2022-07-24 18:03:33 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +42.82)...
2022-07-24 18:03:37 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +42.84)...
2022-07-24 18:03:40 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +43.26)...
2022-07-24 18:03:44 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +43.28)...
2022-07-24 18:03:47 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +43.39)...
2022-07-24 18:03:51 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = +43.05)...
2022-07-24 18:03:54 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = +42.95)...
2022-07-24 18:03:57 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = +43.24)...
2022-07-24 18:03:58 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:04:01 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.06)...
2022-07-24 18:04:02 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 44.80,44.14,42.65,44.54,44.35,43.15,42.84,48.95,41.93,39.19,45.59,44.28,40.39,44.22,41.84,43.42,39.53,41.69,41.27,45.10,40.18,41.07,44.20,42.11,41.27,45.85,39.92,41.05,43.49,41.86,42.73,43.51,45.18,41.68,44.55,46.73,49.73,44.02,41.20,40.03,42.81,41.65,45.19,41.66,38.94,45.46,38.98,47.30,44.32,42.40,42.07,39.76,38.13,39.86,43.82,43.63,42.79,43.76,44.31,41.74,48.31,44.57,44.43,42.65,42.49,41.28,43.18,46.74,40.20,37.84,43.71,52.00,44.21,48.86,47.23,45.42,41.26,38.04,41.23,45.86,43.64,42.44,39.84,44.67,41.81,42.06,43.71,42.90,42.97
2022-07-24 18:04:03 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  4: train = +43.0910(0.64m/561) | dev = +43.1046(0.07m/89) 
2022-07-24 18:04:03 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:04:07 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +43.31)...
2022-07-24 18:04:11 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.18)...
2022-07-24 18:04:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +42.62)...
2022-07-24 18:04:50 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 18:04:50 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=6399, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Linear(in_features=256, out_features=6399, bias=True)
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 18:04:50 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(4,), #param: 8.28M
2022-07-24 18:04:51 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:04:53 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +55.42)...
2022-07-24 18:04:55 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 54.78,54.06,56.97,53.72,52.91,58.19,58.10,55.35,58.76,52.37,52.80,58.11,51.74,57.12,58.09,56.21,54.57,52.66,55.50,58.49,53.84,52.96,53.86,52.93,58.89,55.51,54.32,57.68,57.58,59.65,55.10,58.02,56.65,51.40,56.12,51.77,54.66,54.89,54.24,58.53,55.15,56.81,57.45,51.10,52.30,53.13,57.65,51.98,53.74,62.37,54.88,55.98,58.81,55.51,54.39,58.72,53.73,58.32,55.09,58.53,54.31,56.67,55.16,57.48,52.42,56.98,55.13,52.61,54.65,56.02,51.22,55.65,54.34,56.64,51.94,52.75,57.80,54.26,55.25,58.75,55.47,52.66,54.68,53.56,53.76,55.46,56.34,56.19,58.23
2022-07-24 18:04:55 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 55.4060
2022-07-24 18:04:55 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:05:00 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +46.53)...
2022-07-24 18:05:05 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +46.27)...
2022-07-24 18:05:11 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +45.93)...
2022-07-24 18:05:17 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +44.37)...
2022-07-24 18:05:22 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +45.35)...
2022-07-24 18:05:28 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +44.11)...
2022-07-24 18:05:33 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = +43.26)...
2022-07-24 18:05:38 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = +44.19)...
2022-07-24 18:07:08 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 18:07:08 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(100,), stride=(50,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=1279, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Linear(in_features=256, out_features=1279, bias=True)
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(100,), stride=(50,))
)
2022-07-24 18:07:08 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(4,), #param: 4.38M
2022-07-24 18:07:08 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:07:10 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +53.77)...
2022-07-24 18:07:11 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 58.64,53.03,53.02,52.33,53.12,52.62,55.57,53.60,55.32,52.03,56.04,50.54,54.87,52.76,56.06,53.96,50.56,53.74,51.81,58.61,54.90,51.05,53.87,50.92,56.91,53.04,53.37,51.24,52.19,54.68,57.09,50.52,56.29,55.16,51.48,52.00,55.90,58.00,51.81,52.08,55.21,59.96,53.73,52.64,53.64,51.84,54.61,54.98,50.46,50.84,54.82,54.49,53.39,50.80,55.05,60.81,52.72,52.39,56.41,54.63,56.55,54.34,53.35,50.79,55.42,53.43,52.48,51.56,50.56,51.08,53.96,52.65,52.51,60.37,53.99,52.17,53.20,53.76,55.99,53.94,54.67,54.13,58.88,54.54,55.61,49.33,57.15,52.52,52.06
2022-07-24 18:07:11 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 53.8778
2022-07-24 18:07:11 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:07:15 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +46.41)...
2022-07-24 18:07:19 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = +43.28)...
2022-07-24 18:07:24 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = +43.09)...
2022-07-24 18:07:28 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = +43.58)...
2022-07-24 18:07:32 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = +44.27)...
2022-07-24 18:07:36 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = +44.89)...
2022-07-24 18:10:55 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 18:10:55 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=256, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Linear(in_features=256, out_features=256, bias=True)
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 18:10:55 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(4,), #param: 3.56M
2022-07-24 18:10:55 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:13:59 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 18:13:59 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=256, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Linear(in_features=6399, out_features=6399, bias=True)
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 18:13:59 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:143 - INFO ] Loading model to GPUs:(4,), #param: 44.44M
2022-07-24 18:14:01 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:14:22 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +59.95)...
2022-07-24 18:14:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 60.46,61.46,61.16,63.53,61.10,60.10,61.79,62.84,58.76,61.02,56.60,62.05,60.44,59.95,58.87,59.96,59.58,59.77,58.38,64.42,61.09,60.94,61.21,56.58,56.51,63.26,56.68,56.52,66.15,55.49,57.08,60.79,56.31,57.11,60.85,60.04,60.64,57.27,56.94,65.02,62.23,57.38,58.91,61.65,58.67,58.29,58.69,57.31,63.81,61.89,59.51,63.38,60.05,59.95,56.25,56.35,62.96,57.53,62.64,55.94,64.07,61.88,58.63,59.99,61.82,59.35,62.42,57.98,61.66,62.74,55.14,61.99,60.22,57.43,57.05,57.92,61.30,61.12,57.99,54.67,61.92,56.30,62.07,58.38,59.10,57.84,60.71,62.21,60.11
2022-07-24 18:14:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:221 - INFO ] START FROM EPOCH 0, LOSS = 59.8441
2022-07-24 18:14:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:15:41 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = +1.76)...
2022-07-24 18:16:43 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = -5.38)...
2022-07-24 18:17:45 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = -7.10)...
2022-07-24 18:18:48 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = -7.38)...
2022-07-24 18:20:00 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = -8.26)...
2022-07-24 18:21:13 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = -8.18)...
2022-07-24 18:22:26 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = -8.59)...
2022-07-24 18:23:39 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = -8.73)...
2022-07-24 18:24:45 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = -9.01)...
2022-07-24 18:25:47 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 500 batches(loss = -8.85)...
2022-07-24 18:26:49 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 550 batches(loss = -9.38)...
2022-07-24 18:27:03 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:27:25 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = -9.15)...
2022-07-24 18:27:43 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -8.52,-9.26,-8.70,-9.21,-6.86,-8.56,-8.43,-10.22,-8.72,-8.65,-8.31,-9.75,-10.95,-10.69,-9.07,-8.80,-9.79,-9.80,-8.49,-8.87,-9.41,-8.37,-8.00,-8.16,-10.98,-9.62,-10.90,-8.70,-7.65,-7.96,-9.50,-9.87,-8.93,-7.72,-11.00,-8.92,-10.48,-8.69,-9.51,-8.83,-9.42,-8.50,-9.30,-10.03,-8.26,-10.02,-9.56,-9.62,-9.40,-8.45,-9.06,-9.46,-10.55,-6.65,-10.04,-8.70,-7.45,-9.23,-8.83,-9.80,-10.24,-9.17,-9.35,-9.20,-8.09,-8.53,-9.59,-9.81,-10.68,-9.16,-10.03,-11.01,-10.89,-5.50,-10.60,-9.53,-9.15,-8.05,-10.24,-9.75,-9.06,-9.25,-10.00,-9.56,-9.04,-11.02,-9.85,-7.89,-9.07
2022-07-24 18:27:46 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:247 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  1: train = -7.2275(12.41m/561) | dev = -9.2192(0.68m/89) 
2022-07-24 18:27:49 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:28:52 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 50 batches(loss = -9.53)...
2022-07-24 18:29:57 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 100 batches(loss = -9.89)...
2022-07-24 18:31:00 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 150 batches(loss = -10.31)...
2022-07-24 18:32:06 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 200 batches(loss = -10.36)...
2022-07-24 18:33:09 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 250 batches(loss = -10.58)...
2022-07-24 18:34:13 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 300 batches(loss = -10.37)...
2022-07-24 18:35:17 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 350 batches(loss = -11.13)...
2022-07-24 18:36:20 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 400 batches(loss = -10.80)...
2022-07-24 18:37:23 [/home/disk1/user2/mxy/HolidayWork_gruc/nnet/libs/trainer.py:68 - INFO ] Processed 450 batches(loss = -10.89)...
2022-07-24 16:22:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 16:22:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=256, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Sequential(
    (0): Linear(in_features=256, out_features=637, bias=True)
    (1): ReLU()
    (2): Linear(in_features=637, out_features=498, bias=True)
    (3): ReLU()
    (4): Linear(in_features=498, out_features=256, bias=True)
    (5): ReLU()
  )
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 16:22:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:142 - INFO ] Loading model to GPUs:(0,), #param: 4.10M
2022-07-24 16:22:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 16:24:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 16:24:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Linear(in_features=256, out_features=512, bias=True)
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Sequential(
    (0): Linear(in_features=256, out_features=637, bias=True)
    (1): ReLU()
    (2): Linear(in_features=637, out_features=498, bias=True)
    (3): ReLU()
    (4): Linear(in_features=498, out_features=256, bias=True)
    (5): ReLU()
  )
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 16:24:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:142 - INFO ] Loading model to GPUs:(0,), #param: 4.10M
2022-07-24 16:24:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 16:25:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = +60.56)...
2022-07-24 16:25:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 57.19,63.71,59.54,62.74,61.45,64.49,66.79,57.81,61.63,61.60,58.29,60.67,57.82,61.47,61.61,63.16,59.84,56.38,61.87,58.52,61.63,59.31,57.62,59.51,62.28,58.58,60.04,56.13,63.94,59.29,58.94,62.19,61.06,62.09,61.50,58.92,59.25,63.10,59.60,62.14,53.95,58.02,60.71,61.67,60.98,58.00,61.99,60.24,61.48,67.33,60.40,63.08,61.06,59.55,60.19,57.66,62.02,62.97,59.68,60.65,59.74,64.41,62.51,62.46,62.45,59.31,62.13,60.08,65.53,62.52,60.34,57.97,62.20,64.25,63.52,60.01,61.72,61.53,61.41,59.69,59.62,62.01,62.61,60.69,61.62,62.87,60.42,62.76,59.83
2022-07-24 16:25:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:220 - INFO ] START FROM EPOCH 0, LOSS = 60.9157
2022-07-24 16:25:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 16:26:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = +0.82)...
2022-07-24 16:26:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -5.96)...
2022-07-24 16:27:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -7.00)...
2022-07-24 16:27:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -7.28)...
2022-07-24 16:28:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -7.51)...
2022-07-24 16:29:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -7.54)...
2022-07-24 16:29:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -7.86)...
2022-07-24 16:30:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -8.29)...
2022-07-24 16:30:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -8.16)...
2022-07-24 16:31:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -8.16)...
2022-07-24 16:35:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 16:35:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Sequential(
    (0): Linear(in_features=256, out_features=837, bias=True)
    (1): ReLU()
    (2): Linear(in_features=837, out_features=637, bias=True)
    (3): ReLU()
    (4): Linear(in_features=637, out_features=512, bias=True)
  )
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Sequential(
    (0): Linear(in_features=256, out_features=637, bias=True)
    (1): ReLU()
    (2): Linear(in_features=637, out_features=498, bias=True)
    (3): ReLU()
    (4): Linear(in_features=498, out_features=256, bias=True)
    (5): ReLU()
  )
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 16:35:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:142 - INFO ] Loading model to GPUs:(0,), #param: 5.04M
2022-07-24 16:35:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 16:37:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 16:37:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Sequential(
    (0): Linear(in_features=256, out_features=837, bias=True)
    (1): ReLU()
    (2): Linear(in_features=837, out_features=637, bias=True)
    (3): ReLU()
    (4): Linear(in_features=637, out_features=512, bias=True)
  )
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Sequential(
    (0): Linear(in_features=256, out_features=637, bias=True)
    (1): ReLU()
    (2): Linear(in_features=637, out_features=498, bias=True)
    (3): ReLU()
    (4): Linear(in_features=498, out_features=256, bias=True)
    (5): ReLU()
  )
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 16:37:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:142 - INFO ] Loading model to GPUs:(0,), #param: 5.04M
2022-07-24 16:37:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 16:38:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = +31.51)...
2022-07-24 16:38:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 32.49,31.19,30.49,29.60,30.67,31.27,30.21,33.72,31.56,30.63,32.60,29.93,34.33,28.18,33.84,32.87,29.88,32.09,33.07,31.95,31.54,31.62,33.70,29.31,29.15,33.95,30.26,30.63,30.22,30.86,33.78,30.80,32.27,34.16,28.90,35.50,27.24,30.11,29.10,31.35,32.57,30.04,31.89,31.99,33.30,29.14,30.39,33.26,35.48,32.21,28.85,30.64,33.59,31.40,27.43,30.88,33.06,31.21,33.65,32.01,32.45,29.91,30.11,34.92,31.30,32.06,32.32,31.25,28.87,30.56,33.29,33.27,33.19,31.86,28.92,31.49,31.37,32.40,31.07,29.85,32.61,31.82,30.33,32.10,32.96,30.60,31.55,29.74,30.17
2022-07-24 16:38:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:220 - INFO ] START FROM EPOCH 0, LOSS = 31.4646
2022-07-24 16:38:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 16:38:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -3.05)...
2022-07-24 16:39:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:172 - INFO ] Create optimizer adam: {'lr': 0.001, 'weight_decay': 1e-05}
2022-07-24 16:39:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:141 - INFO ] Model summary:
NET(
  (encoder_1d): Conv1D(1, 256, kernel_size=(20,), stride=(10,))
  (gru_net): GRUC(
    (gru): GRU(512, 512, num_layers=2, batch_first=True, dropout=0.2)
    (linear2): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
  )
  (linear1): Sequential(
    (0): Linear(in_features=256, out_features=837, bias=True)
    (1): ReLU()
    (2): Linear(in_features=837, out_features=637, bias=True)
    (3): ReLU()
    (4): Linear(in_features=637, out_features=512, bias=True)
  )
  (mask): Conv1D(256, 256, kernel_size=(1,), stride=(1,))
  (linear2): Sequential(
    (0): Linear(in_features=256, out_features=637, bias=True)
    (1): ReLU()
    (2): Linear(in_features=637, out_features=498, bias=True)
    (3): ReLU()
    (4): Linear(in_features=498, out_features=256, bias=True)
    (5): ReLU()
  )
  (decoder_1d): ConvTrans1D(256, 1, kernel_size=(20,), stride=(10,))
)
2022-07-24 16:39:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:142 - INFO ] Loading model to GPUs:(0,), #param: 5.04M
2022-07-24 16:39:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 16:39:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = +23.49)...
2022-07-24 16:39:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: 23.99,23.79,23.01,23.02,23.20,24.23,22.97,24.69,23.32,22.57,23.94,22.85,24.22,22.23,24.13,24.28,23.05,23.64,24.92,23.35,24.28,23.36,24.28,23.06,22.35,23.48,23.06,24.13,23.37,23.33,22.85,22.97,23.79,23.47,22.43,24.34,21.90,23.10,22.31,23.19,25.06,22.92,23.06,24.11,24.53,23.34,23.15,24.14,23.45,24.20,22.43,23.30,23.43,23.64,22.26,22.94,23.17,23.01,23.84,24.04,23.30,23.07,22.94,23.64,23.26,23.40,22.91,24.04,22.29,23.55,23.85,23.97,23.69,23.65,22.11,23.49,24.04,24.58,22.84,23.05,23.54,23.43,22.15,23.08,23.69,22.49,23.28,22.82,24.14
2022-07-24 16:39:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:220 - INFO ] START FROM EPOCH 0, LOSS = 23.4013
2022-07-24 16:39:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 16:40:34 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -3.93)...
2022-07-24 16:41:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -8.31)...
2022-07-24 16:41:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -9.01)...
2022-07-24 16:42:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -9.92)...
2022-07-24 16:43:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -9.93)...
2022-07-24 16:43:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -10.93)...
2022-07-24 16:44:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -11.40)...
2022-07-24 16:45:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -10.90)...
2022-07-24 16:45:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -11.57)...
2022-07-24 16:46:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -12.09)...
2022-07-24 16:47:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -12.21)...
2022-07-24 16:47:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 16:47:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -12.29)...
2022-07-24 16:47:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -11.48,-12.80,-11.56,-11.95,-9.53,-11.93,-11.39,-13.86,-11.32,-12.16,-11.57,-13.31,-14.19,-13.29,-12.19,-12.15,-13.18,-13.04,-11.69,-12.05,-12.55,-11.92,-11.08,-11.23,-14.43,-13.05,-14.12,-12.26,-11.40,-11.27,-12.33,-12.99,-12.48,-10.66,-14.05,-11.73,-13.55,-11.65,-12.36,-12.34,-12.23,-11.25,-11.75,-13.64,-10.84,-13.21,-12.44,-12.99,-11.79,-12.17,-11.72,-12.72,-13.82,-10.07,-13.14,-11.74,-10.24,-12.17,-12.33,-13.48,-13.39,-12.09,-12.67,-12.07,-11.28,-11.47,-12.97,-13.37,-13.77,-12.87,-13.26,-13.77,-13.66,-8.76,-13.90,-13.28,-12.53,-11.36,-13.59,-12.83,-11.89,-12.51,-13.05,-12.62,-12.35,-13.95,-13.32,-10.43,-12.52
2022-07-24 16:47:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  1: train = -10.0697(7.46m/561) | dev = -12.3748(0.46m/89) 
2022-07-24 16:47:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 16:48:29 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -12.17)...
2022-07-24 16:49:09 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -13.08)...
2022-07-24 16:49:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -12.37)...
2022-07-24 16:50:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -12.84)...
2022-07-24 16:51:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -12.66)...
2022-07-24 16:51:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -13.09)...
2022-07-24 16:52:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -13.10)...
2022-07-24 16:53:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -13.61)...
2022-07-24 16:53:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -13.31)...
2022-07-24 16:54:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -13.38)...
2022-07-24 16:55:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -13.29)...
2022-07-24 16:55:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 16:55:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -13.50)...
2022-07-24 16:55:43 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -12.77,-14.58,-12.68,-13.21,-10.61,-12.97,-12.61,-15.03,-12.37,-13.55,-12.79,-14.46,-15.48,-14.45,-13.44,-13.30,-14.33,-14.13,-13.10,-13.07,-13.61,-12.94,-12.13,-12.38,-15.82,-14.62,-15.48,-13.38,-12.86,-12.57,-13.34,-14.32,-14.05,-11.93,-15.31,-12.92,-14.74,-12.68,-13.31,-13.66,-13.40,-12.10,-13.00,-15.13,-11.87,-14.29,-13.53,-14.26,-12.99,-13.34,-12.68,-13.87,-14.97,-11.39,-14.55,-13.23,-11.24,-13.39,-13.71,-14.84,-14.59,-13.29,-13.85,-13.23,-12.56,-12.78,-14.40,-14.84,-14.89,-13.98,-14.73,-14.97,-14.31,-9.91,-15.22,-15.04,-13.64,-12.63,-15.07,-14.01,-12.91,-13.62,-14.01,-13.75,-13.66,-15.12,-14.41,-11.47,-13.69
2022-07-24 16:55:43 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  2: train = -12.9974(7.45m/561) | dev = -13.5883(0.46m/89) 
2022-07-24 16:55:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 16:56:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -13.21)...
2022-07-24 16:57:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -12.68)...
2022-07-24 16:57:43 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -13.62)...
2022-07-24 16:58:23 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -13.57)...
2022-07-24 16:59:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -13.59)...
2022-07-24 16:59:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -13.59)...
2022-07-24 17:00:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -13.64)...
2022-07-24 17:01:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -13.69)...
2022-07-24 17:01:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -13.68)...
2022-07-24 17:02:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -13.76)...
2022-07-24 17:03:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -13.90)...
2022-07-24 17:03:10 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:03:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -13.89)...
2022-07-24 17:03:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -13.10,-15.14,-13.06,-13.68,-11.01,-13.64,-13.16,-15.27,-12.67,-13.99,-13.33,-14.86,-15.85,-14.65,-13.87,-13.64,-14.73,-14.52,-13.43,-13.59,-13.86,-13.43,-12.56,-12.72,-16.11,-15.03,-15.73,-13.77,-13.26,-12.96,-13.58,-14.51,-14.20,-12.17,-15.70,-13.24,-15.07,-13.06,-13.82,-14.14,-13.75,-12.58,-13.32,-15.40,-12.36,-14.60,-14.09,-14.65,-13.41,-14.09,-13.01,-14.41,-15.21,-11.81,-14.94,-13.53,-11.68,-13.85,-14.14,-15.12,-15.04,-13.58,-14.33,-13.61,-13.07,-13.23,-14.61,-15.27,-15.09,-14.62,-15.11,-15.27,-15.00,-10.43,-15.69,-15.51,-13.98,-13.00,-15.33,-14.34,-13.43,-13.98,-14.46,-14.13,-14.06,-15.48,-14.71,-11.95,-14.10
2022-07-24 17:03:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  3: train = -13.5497(7.44m/561) | dev = -13.9825(0.45m/89) 
2022-07-24 17:03:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:04:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.01)...
2022-07-24 17:04:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -13.79)...
2022-07-24 17:05:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -13.77)...
2022-07-24 17:06:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -14.12)...
2022-07-24 17:06:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -14.36)...
2022-07-24 17:07:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -14.17)...
2022-07-24 17:08:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -14.13)...
2022-07-24 17:08:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -13.64)...
2022-07-24 17:09:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -13.96)...
2022-07-24 17:10:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -13.92)...
2022-07-24 17:10:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -14.42)...
2022-07-24 17:11:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:11:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.27)...
2022-07-24 17:11:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -13.27,-15.55,-13.35,-14.01,-11.47,-13.77,-13.48,-15.68,-13.03,-14.47,-13.85,-15.18,-16.22,-15.36,-14.31,-14.15,-14.99,-14.82,-13.72,-13.81,-14.40,-13.86,-12.86,-12.89,-16.40,-15.43,-16.40,-14.30,-13.57,-13.48,-14.15,-15.01,-15.09,-12.61,-15.91,-13.66,-15.35,-13.48,-14.14,-14.46,-14.09,-12.86,-13.54,-15.67,-12.67,-14.96,-14.37,-14.93,-13.79,-14.50,-13.38,-14.71,-15.63,-12.13,-15.32,-14.01,-12.20,-14.38,-14.45,-15.50,-15.21,-13.89,-14.60,-14.22,-13.62,-13.52,-14.96,-15.51,-15.53,-14.95,-15.34,-15.70,-15.46,-10.71,-16.23,-15.89,-14.29,-13.40,-15.69,-14.75,-13.93,-14.33,-14.68,-14.37,-14.58,-15.73,-15.14,-12.29,-14.46
2022-07-24 17:11:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  4: train = -14.0200(7.46m/561) | dev = -14.3600(0.45m/89) 
2022-07-24 17:11:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:12:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.41)...
2022-07-24 17:12:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -14.22)...
2022-07-24 17:13:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -14.35)...
2022-07-24 17:14:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -14.58)...
2022-07-24 17:14:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -14.34)...
2022-07-24 17:15:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -14.00)...
2022-07-24 17:16:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -14.01)...
2022-07-24 17:16:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -14.17)...
2022-07-24 17:17:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -14.27)...
2022-07-24 17:18:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -14.35)...
2022-07-24 17:18:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -14.51)...
2022-07-24 17:19:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:19:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.22)...
2022-07-24 17:19:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -13.24,-15.55,-13.40,-13.98,-11.38,-13.81,-13.50,-15.62,-13.12,-14.43,-13.72,-15.26,-16.20,-15.30,-14.29,-14.06,-14.86,-14.85,-14.05,-13.93,-14.30,-13.84,-12.84,-12.98,-16.35,-15.24,-16.12,-14.10,-13.54,-13.37,-14.06,-15.07,-14.58,-12.51,-15.77,-13.64,-15.37,-13.25,-14.10,-14.44,-14.19,-12.81,-13.66,-15.78,-12.55,-15.01,-14.05,-14.88,-13.82,-14.46,-13.28,-14.69,-15.49,-12.13,-15.40,-13.75,-12.13,-14.35,-14.51,-15.35,-15.29,-13.90,-14.39,-14.20,-13.53,-13.44,-14.91,-15.55,-15.54,-15.03,-15.41,-15.66,-15.47,-10.86,-16.05,-15.86,-14.21,-13.40,-15.66,-14.80,-13.81,-14.45,-14.77,-14.28,-14.51,-15.67,-15.07,-12.31,-14.53
2022-07-24 17:19:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  5: train = -14.2984(7.44m/561) | dev = -14.3238(0.45m/89) | no impr, best = -14.3600
2022-07-24 17:19:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:20:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.74)...
2022-07-24 17:20:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -14.80)...
2022-07-24 17:21:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -14.41)...
2022-07-24 17:22:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -14.30)...
2022-07-24 17:22:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -14.29)...
2022-07-24 17:23:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -13.84)...
2022-07-24 17:24:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -14.56)...
2022-07-24 17:24:46 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -14.72)...
2022-07-24 17:25:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -14.27)...
2022-07-24 17:26:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -14.60)...
2022-07-24 17:26:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -14.55)...
2022-07-24 17:26:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:27:10 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.60)...
2022-07-24 17:27:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -13.75,-15.97,-13.70,-14.44,-11.59,-14.23,-13.86,-15.88,-13.40,-14.79,-14.23,-15.58,-16.55,-15.69,-14.74,-14.58,-15.33,-15.12,-13.58,-14.25,-14.73,-14.34,-13.31,-13.21,-16.84,-15.65,-16.66,-14.55,-13.94,-13.83,-14.44,-15.48,-15.09,-12.91,-16.18,-13.99,-15.70,-13.73,-14.39,-14.87,-14.32,-13.29,-13.92,-16.11,-13.08,-15.35,-14.51,-15.22,-14.25,-14.90,-13.72,-15.07,-15.85,-12.54,-15.78,-14.42,-12.59,-14.67,-14.92,-15.85,-15.77,-14.28,-14.88,-14.61,-14.07,-13.95,-15.32,-15.89,-15.76,-15.27,-15.70,-16.03,-15.75,-11.20,-16.69,-16.25,-14.42,-13.80,-16.01,-15.10,-14.18,-14.58,-14.99,-14.66,-14.94,-15.95,-15.50,-12.77,-14.81
2022-07-24 17:27:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  6: train = -14.4582(7.45m/561) | dev = -14.7032(0.45m/89) 
2022-07-24 17:27:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:28:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.83)...
2022-07-24 17:28:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -14.76)...
2022-07-24 17:29:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -14.78)...
2022-07-24 17:30:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -14.65)...
2022-07-24 17:30:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -14.85)...
2022-07-24 17:31:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -14.86)...
2022-07-24 17:32:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -14.73)...
2022-07-24 17:32:41 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -14.51)...
2022-07-24 17:33:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -14.75)...
2022-07-24 17:34:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -14.95)...
2022-07-24 17:34:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -14.88)...
2022-07-24 17:34:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:35:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.70)...
2022-07-24 17:35:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -13.67,-16.10,-13.83,-14.36,-11.96,-14.35,-13.87,-16.13,-13.26,-14.84,-14.29,-15.66,-16.75,-16.00,-14.71,-14.65,-15.42,-15.20,-14.11,-14.37,-14.95,-14.12,-13.30,-13.20,-16.86,-15.82,-16.72,-14.65,-13.96,-13.97,-14.66,-15.46,-15.25,-13.00,-16.36,-14.13,-15.80,-13.81,-14.49,-14.98,-14.44,-13.20,-13.52,-16.36,-13.13,-15.54,-14.86,-15.36,-14.42,-15.01,-13.79,-15.22,-16.12,-12.62,-15.84,-14.62,-12.53,-14.94,-14.49,-15.90,-15.54,-14.40,-14.96,-14.98,-14.15,-14.02,-15.24,-16.08,-15.97,-15.45,-15.98,-16.14,-15.88,-11.38,-16.82,-16.36,-14.58,-13.77,-15.93,-15.21,-14.37,-14.87,-15.08,-14.72,-15.02,-16.08,-15.66,-12.82,-14.98
2022-07-24 17:35:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  7: train = -14.7827(7.45m/561) | dev = -14.8021(0.46m/89) 
2022-07-24 17:35:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:35:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.14)...
2022-07-24 17:36:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -14.83)...
2022-07-24 17:37:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -14.75)...
2022-07-24 17:37:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -14.95)...
2022-07-24 17:38:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -14.91)...
2022-07-24 17:39:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -14.98)...
2022-07-24 17:39:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -14.75)...
2022-07-24 17:40:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.14)...
2022-07-24 17:41:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.10)...
2022-07-24 17:41:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -14.73)...
2022-07-24 17:42:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -14.85)...
2022-07-24 17:42:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:43:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.84)...
2022-07-24 17:43:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.01,-16.20,-14.05,-14.50,-12.15,-14.44,-13.99,-16.22,-13.62,-15.03,-14.52,-15.74,-16.81,-15.63,-14.93,-14.84,-15.51,-15.30,-14.03,-14.48,-15.08,-14.66,-13.50,-13.41,-16.57,-15.93,-16.86,-14.79,-14.21,-14.17,-14.79,-15.74,-15.48,-13.21,-16.38,-14.30,-15.90,-13.94,-14.61,-15.11,-14.73,-13.47,-14.08,-16.35,-13.30,-15.63,-14.95,-15.31,-14.41,-15.06,-13.97,-15.22,-16.10,-12.83,-15.93,-14.82,-12.80,-15.11,-15.12,-16.03,-15.88,-14.39,-14.99,-15.02,-14.33,-14.16,-15.54,-16.21,-15.98,-15.49,-16.07,-16.26,-15.88,-11.52,-16.86,-16.51,-14.60,-14.08,-16.01,-15.34,-14.50,-15.08,-15.14,-14.84,-15.34,-16.13,-15.74,-13.01,-15.42
2022-07-24 17:43:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  8: train = -14.9029(7.46m/561) | dev = -14.9461(0.45m/89) 
2022-07-24 17:43:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:43:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.84)...
2022-07-24 17:44:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.11)...
2022-07-24 17:45:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.28)...
2022-07-24 17:45:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.08)...
2022-07-24 17:46:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -14.63)...
2022-07-24 17:47:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -14.93)...
2022-07-24 17:47:50 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.02)...
2022-07-24 17:48:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -14.88)...
2022-07-24 17:49:10 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.19)...
2022-07-24 17:49:50 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.33)...
2022-07-24 17:50:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -14.82)...
2022-07-24 17:50:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:50:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.93)...
2022-07-24 17:51:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.07,-16.23,-14.05,-14.58,-12.19,-14.47,-14.20,-16.11,-13.76,-15.10,-14.63,-15.83,-16.93,-15.76,-15.01,-14.97,-15.58,-15.36,-14.56,-14.66,-15.22,-14.82,-13.64,-13.42,-16.96,-15.94,-16.93,-14.84,-14.25,-14.15,-14.77,-15.67,-15.53,-13.41,-16.62,-14.40,-16.00,-14.04,-14.64,-15.18,-14.75,-13.59,-14.22,-16.36,-13.41,-15.76,-14.91,-15.51,-14.44,-15.11,-14.00,-15.46,-16.20,-12.85,-16.00,-14.83,-12.87,-15.19,-15.20,-16.10,-16.02,-14.54,-15.12,-15.06,-14.39,-14.33,-15.51,-16.23,-16.19,-15.64,-16.26,-16.23,-16.04,-11.59,-16.69,-16.61,-14.84,-14.23,-16.22,-15.36,-14.60,-15.16,-15.38,-14.89,-15.26,-16.26,-15.79,-13.03,-15.10
2022-07-24 17:51:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch  9: train = -15.0160(7.44m/561) | dev = -15.0317(0.45m/89) 
2022-07-24 17:51:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:51:46 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.48)...
2022-07-24 17:52:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -14.85)...
2022-07-24 17:53:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.04)...
2022-07-24 17:53:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -14.99)...
2022-07-24 17:54:25 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.39)...
2022-07-24 17:55:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -14.96)...
2022-07-24 17:55:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.24)...
2022-07-24 17:56:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.11)...
2022-07-24 17:57:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.11)...
2022-07-24 17:57:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.07)...
2022-07-24 17:58:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.15)...
2022-07-24 17:58:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 17:58:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.90)...
2022-07-24 17:59:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.08,-16.17,-14.19,-14.72,-12.24,-14.41,-14.08,-16.21,-13.77,-15.07,-14.64,-15.81,-16.75,-15.78,-15.05,-14.89,-15.60,-15.36,-14.66,-14.52,-15.14,-14.78,-13.58,-13.44,-17.01,-15.98,-16.72,-14.81,-14.19,-14.23,-14.83,-15.78,-15.33,-13.34,-16.60,-14.49,-15.94,-14.04,-14.62,-15.09,-14.60,-13.44,-14.13,-16.48,-13.40,-15.58,-14.72,-15.38,-14.50,-15.08,-14.04,-15.30,-16.11,-12.80,-15.85,-14.76,-12.93,-15.21,-15.04,-15.98,-15.97,-14.43,-15.03,-15.08,-14.38,-14.27,-15.49,-16.26,-15.95,-15.64,-16.16,-16.25,-15.98,-11.69,-16.63,-16.54,-14.65,-14.17,-16.15,-15.44,-14.62,-15.07,-15.24,-15.01,-15.29,-16.21,-15.78,-13.00,-15.48
2022-07-24 17:59:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 10: train = -15.1408(7.44m/561) | dev = -15.0012(0.46m/89) | no impr, best = -15.0317
2022-07-24 17:59:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 17:59:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.18)...
2022-07-24 18:00:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.50)...
2022-07-24 18:00:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.23)...
2022-07-24 18:01:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.43)...
2022-07-24 18:02:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.33)...
2022-07-24 18:02:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -14.92)...
2022-07-24 18:03:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.09)...
2022-07-24 18:04:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -14.99)...
2022-07-24 18:04:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.28)...
2022-07-24 18:05:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -14.89)...
2022-07-24 18:06:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.23)...
2022-07-24 18:06:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:06:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -14.98)...
2022-07-24 18:06:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.23,-16.29,-14.16,-14.73,-12.30,-14.58,-14.22,-16.19,-13.75,-15.14,-14.72,-15.87,-16.92,-16.10,-15.11,-15.00,-15.69,-15.47,-14.62,-14.67,-15.31,-14.68,-13.69,-13.46,-16.94,-16.13,-16.74,-14.84,-14.33,-14.23,-14.71,-15.83,-15.60,-13.45,-16.55,-14.32,-16.05,-13.97,-14.66,-15.28,-14.90,-13.48,-14.17,-16.25,-13.48,-15.77,-15.03,-15.52,-14.57,-15.21,-14.05,-15.52,-16.29,-12.86,-16.13,-15.05,-13.04,-15.28,-15.25,-16.03,-16.01,-14.44,-15.27,-15.20,-14.43,-14.32,-15.62,-16.25,-16.24,-15.71,-16.27,-16.37,-16.09,-11.67,-16.85,-16.63,-14.83,-14.25,-16.32,-15.48,-14.70,-15.18,-15.42,-14.98,-15.52,-16.35,-15.88,-13.20,-15.60
2022-07-24 18:06:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 11: train = -15.1877(7.44m/561) | dev = -15.0955(0.46m/89) 
2022-07-24 18:06:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:07:34 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.34)...
2022-07-24 18:08:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.37)...
2022-07-24 18:08:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.23)...
2022-07-24 18:09:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.54)...
2022-07-24 18:10:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.06)...
2022-07-24 18:10:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.22)...
2022-07-24 18:11:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.05)...
2022-07-24 18:12:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -14.94)...
2022-07-24 18:12:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.45)...
2022-07-24 18:13:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.45)...
2022-07-24 18:14:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.47)...
2022-07-24 18:14:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:14:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.04)...
2022-07-24 18:14:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.20,-16.34,-14.27,-14.82,-12.35,-14.69,-14.26,-16.36,-13.88,-15.22,-14.77,-15.94,-16.97,-16.09,-15.11,-15.09,-15.64,-15.53,-14.82,-14.68,-15.37,-14.84,-13.65,-13.43,-17.01,-15.68,-16.96,-14.93,-14.34,-14.26,-14.95,-15.72,-15.47,-13.54,-16.68,-14.58,-16.04,-14.15,-14.79,-15.33,-14.83,-13.64,-14.17,-16.65,-13.48,-15.87,-14.86,-15.65,-14.61,-15.26,-14.14,-15.61,-16.35,-13.04,-15.93,-15.02,-13.00,-15.09,-15.30,-16.22,-16.15,-14.61,-15.17,-15.19,-14.51,-14.40,-15.78,-16.34,-16.29,-15.87,-16.30,-16.47,-16.14,-11.36,-17.09,-16.71,-14.82,-14.27,-16.36,-15.43,-14.74,-14.87,-15.46,-14.66,-15.34,-16.32,-15.92,-13.10,-15.57
2022-07-24 18:14:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 12: train = -15.2744(7.44m/561) | dev = -15.1324(0.45m/89) 
2022-07-24 18:14:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:15:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.21)...
2022-07-24 18:16:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.38)...
2022-07-24 18:16:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.52)...
2022-07-24 18:17:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.26)...
2022-07-24 18:18:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.37)...
2022-07-24 18:18:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.48)...
2022-07-24 18:19:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.48)...
2022-07-24 18:20:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.53)...
2022-07-24 18:20:46 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.21)...
2022-07-24 18:21:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.61)...
2022-07-24 18:22:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.56)...
2022-07-24 18:22:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:22:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.01)...
2022-07-24 18:22:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.19,-16.23,-14.30,-14.58,-12.48,-14.62,-14.29,-16.15,-13.87,-15.10,-14.78,-15.88,-16.76,-16.16,-15.18,-15.04,-15.67,-15.55,-14.80,-14.78,-15.27,-14.91,-13.86,-13.45,-17.00,-15.94,-16.80,-14.96,-14.36,-14.37,-14.98,-15.91,-15.29,-13.53,-16.49,-14.50,-16.01,-14.11,-14.67,-15.27,-14.78,-13.67,-14.21,-16.36,-13.54,-15.80,-14.74,-15.53,-14.54,-15.21,-14.27,-15.40,-16.09,-12.95,-16.06,-15.02,-13.15,-15.44,-15.07,-16.11,-16.02,-14.58,-15.12,-15.31,-14.51,-14.37,-15.63,-16.19,-16.21,-15.63,-16.33,-16.38,-16.15,-11.82,-16.91,-16.53,-14.88,-14.23,-16.25,-15.61,-14.72,-15.08,-15.46,-15.04,-15.50,-16.22,-15.86,-13.11,-15.57
2022-07-24 18:22:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 13: train = -15.4188(7.44m/561) | dev = -15.1153(0.46m/89) | no impr, best = -15.1324
2022-07-24 18:22:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:23:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.37)...
2022-07-24 18:24:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.27)...
2022-07-24 18:24:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.43)...
2022-07-24 18:25:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.57)...
2022-07-24 18:26:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.79)...
2022-07-24 18:26:41 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.66)...
2022-07-24 18:27:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.35)...
2022-07-24 18:28:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.25)...
2022-07-24 18:28:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.58)...
2022-07-24 18:29:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.81)...
2022-07-24 18:30:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.48)...
2022-07-24 18:30:09 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:30:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.27)...
2022-07-24 18:30:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.46,-16.54,-14.52,-14.81,-12.53,-14.86,-14.51,-16.59,-14.09,-15.42,-15.00,-16.16,-17.17,-16.38,-15.38,-15.37,-15.93,-15.61,-14.94,-14.88,-15.56,-15.11,-13.97,-13.71,-17.42,-16.29,-17.02,-15.19,-14.55,-14.53,-15.11,-16.18,-15.97,-13.73,-16.88,-14.73,-16.26,-14.37,-14.94,-15.56,-15.01,-13.75,-14.48,-16.79,-13.67,-16.10,-15.29,-15.78,-14.79,-15.47,-14.41,-15.79,-16.59,-13.28,-16.43,-15.22,-13.29,-15.65,-15.61,-16.50,-16.50,-14.94,-15.43,-15.40,-14.78,-14.69,-15.96,-16.81,-16.51,-16.03,-16.53,-16.63,-16.35,-11.96,-17.16,-16.94,-14.99,-14.54,-16.58,-15.71,-14.99,-15.39,-15.60,-15.21,-15.65,-16.50,-16.14,-13.39,-15.84
2022-07-24 18:30:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 14: train = -15.5074(7.44m/561) | dev = -15.3852(0.46m/89) 
2022-07-24 18:30:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:31:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.74)...
2022-07-24 18:31:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.12)...
2022-07-24 18:32:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -14.72)...
2022-07-24 18:33:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.19)...
2022-07-24 18:33:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.72)...
2022-07-24 18:34:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.60)...
2022-07-24 18:35:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.57)...
2022-07-24 18:35:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.26)...
2022-07-24 18:36:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -14.92)...
2022-07-24 18:37:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.08)...
2022-07-24 18:37:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.22)...
2022-07-24 18:38:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:38:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.23)...
2022-07-24 18:38:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.38,-16.50,-14.43,-14.79,-12.48,-14.85,-14.47,-16.55,-14.06,-15.41,-14.89,-16.08,-17.17,-16.16,-15.29,-15.24,-15.89,-15.72,-14.96,-14.80,-15.49,-15.09,-13.91,-13.62,-17.39,-16.24,-17.14,-15.13,-14.47,-14.56,-15.16,-16.14,-15.89,-13.76,-16.85,-14.71,-16.20,-14.35,-14.80,-15.45,-15.11,-13.77,-14.41,-16.88,-13.67,-16.03,-15.21,-15.81,-14.72,-15.48,-14.31,-15.59,-16.56,-13.00,-16.35,-15.17,-13.34,-15.52,-15.46,-16.33,-16.43,-14.96,-15.35,-15.40,-14.67,-14.58,-15.92,-16.59,-16.43,-15.97,-16.52,-16.59,-16.31,-12.00,-17.26,-16.94,-14.95,-14.44,-16.52,-15.69,-14.93,-15.36,-15.65,-15.17,-15.46,-16.52,-16.09,-13.41,-15.72
2022-07-24 18:38:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 15: train = -15.2745(7.44m/561) | dev = -15.3373(0.45m/89) | no impr, best = -15.3852
2022-07-24 18:38:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:39:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.51)...
2022-07-24 18:39:50 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -14.92)...
2022-07-24 18:40:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.44)...
2022-07-24 18:41:10 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.49)...
2022-07-24 18:41:50 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.63)...
2022-07-24 18:42:29 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.44)...
2022-07-24 18:43:09 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.56)...
2022-07-24 18:43:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.55)...
2022-07-24 18:44:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.29)...
2022-07-24 18:45:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.63)...
2022-07-24 18:45:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.55)...
2022-07-24 18:45:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:46:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.23)...
2022-07-24 18:46:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.50,-16.43,-14.39,-14.82,-12.60,-14.87,-14.53,-16.44,-14.04,-15.34,-15.03,-16.08,-17.10,-16.32,-15.33,-15.27,-15.89,-15.65,-15.01,-15.00,-15.47,-14.97,-13.91,-13.64,-17.34,-16.28,-16.75,-15.12,-14.58,-14.52,-15.08,-16.14,-16.10,-13.85,-16.79,-14.83,-16.21,-14.25,-14.94,-15.53,-15.08,-13.76,-14.45,-16.85,-13.63,-16.00,-14.88,-15.78,-14.64,-15.45,-14.40,-15.67,-16.37,-13.08,-16.38,-15.21,-13.18,-15.49,-15.42,-16.37,-16.52,-14.89,-15.47,-15.44,-14.64,-14.61,-15.82,-16.67,-16.45,-15.89,-16.49,-16.62,-16.34,-11.90,-17.10,-16.84,-15.09,-14.43,-16.58,-15.83,-14.98,-15.24,-15.73,-15.21,-15.64,-16.45,-16.09,-13.83,-15.83
2022-07-24 18:46:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 16: train = -15.4507(7.43m/561) | dev = -15.3439(0.45m/89) | no impr, best = -15.3852
2022-07-24 18:46:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:47:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.28)...
2022-07-24 18:47:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.85)...
2022-07-24 18:48:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.74)...
2022-07-24 18:49:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.55)...
2022-07-24 18:49:43 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.69)...
2022-07-24 18:50:23 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.66)...
2022-07-24 18:51:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.66)...
2022-07-24 18:51:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.75)...
2022-07-24 18:52:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.37)...
2022-07-24 18:53:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.85)...
2022-07-24 18:53:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.62)...
2022-07-24 18:53:50 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 18:54:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.30)...
2022-07-24 18:54:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.56,-16.58,-14.48,-14.85,-12.54,-14.98,-14.62,-16.65,-14.06,-15.45,-15.12,-16.19,-17.18,-16.38,-15.43,-15.36,-15.91,-15.70,-15.02,-15.01,-15.61,-15.17,-14.00,-13.65,-17.49,-16.40,-16.91,-15.16,-14.61,-14.64,-15.09,-16.20,-16.07,-13.91,-16.89,-14.81,-16.28,-14.35,-14.94,-15.58,-15.21,-13.99,-14.59,-16.78,-13.63,-16.14,-14.99,-15.81,-14.85,-15.41,-14.53,-15.87,-16.40,-13.27,-16.51,-15.38,-13.39,-15.63,-15.68,-16.56,-16.56,-14.99,-15.52,-15.62,-14.75,-14.71,-16.04,-17.07,-16.63,-16.00,-16.64,-16.70,-16.42,-12.00,-17.39,-16.94,-15.10,-14.55,-16.66,-15.93,-15.06,-15.33,-15.77,-15.31,-15.63,-16.61,-16.14,-13.50,-15.91
2022-07-24 18:54:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 17: train = -15.6431(7.43m/561) | dev = -15.4377(0.45m/89) 
2022-07-24 18:54:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 18:54:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.49)...
2022-07-24 18:55:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.75)...
2022-07-24 18:56:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.83)...
2022-07-24 18:56:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.58)...
2022-07-24 18:57:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.70)...
2022-07-24 18:58:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.85)...
2022-07-24 18:58:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.86)...
2022-07-24 18:59:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.84)...
2022-07-24 19:00:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.72)...
2022-07-24 19:00:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.59)...
2022-07-24 19:01:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.70)...
2022-07-24 19:01:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:02:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.07)...
2022-07-24 19:02:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.17,-16.33,-14.33,-14.80,-12.47,-14.72,-14.42,-16.46,-13.92,-15.29,-14.84,-16.04,-17.07,-16.07,-15.21,-14.99,-15.75,-15.52,-14.62,-14.71,-15.34,-14.73,-13.82,-13.56,-16.75,-16.01,-17.15,-15.02,-14.48,-14.36,-14.82,-15.87,-15.47,-13.58,-16.71,-14.52,-16.03,-14.01,-14.75,-15.44,-14.67,-13.65,-14.34,-16.70,-13.48,-15.92,-14.97,-15.72,-14.54,-15.40,-14.08,-15.58,-16.35,-13.18,-16.20,-14.87,-13.16,-15.12,-15.35,-16.25,-16.23,-14.68,-14.99,-15.31,-14.74,-14.43,-15.58,-16.47,-16.20,-15.81,-16.43,-16.47,-16.18,-11.79,-17.15,-16.73,-15.09,-14.29,-16.07,-15.47,-14.71,-15.24,-15.53,-14.89,-15.25,-16.38,-15.96,-13.29,-15.65
2022-07-24 19:02:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 18: train = -15.7086(7.43m/561) | dev = -15.1766(0.45m/89) | no impr, best = -15.4377
2022-07-24 19:02:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:02:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.46)...
2022-07-24 19:03:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.70)...
2022-07-24 19:04:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.64)...
2022-07-24 19:04:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.83)...
2022-07-24 19:05:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.56)...
2022-07-24 19:06:10 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.88)...
2022-07-24 19:06:50 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.62)...
2022-07-24 19:07:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.80)...
2022-07-24 19:08:09 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.45)...
2022-07-24 19:08:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.48)...
2022-07-24 19:09:29 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.00)...
2022-07-24 19:09:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:09:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.33)...
2022-07-24 19:10:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.53,-16.62,-14.50,-14.82,-12.63,-15.00,-14.63,-16.60,-14.11,-15.46,-15.15,-16.16,-17.27,-16.34,-15.47,-15.39,-15.99,-15.77,-14.67,-14.99,-15.66,-15.22,-14.10,-14.02,-17.04,-16.40,-16.95,-15.20,-14.64,-14.71,-15.20,-16.26,-16.35,-14.00,-16.83,-14.83,-16.33,-14.37,-14.93,-15.61,-15.28,-13.87,-14.64,-16.92,-13.82,-16.11,-15.00,-15.78,-14.72,-15.56,-14.58,-15.84,-16.66,-13.30,-16.49,-15.37,-13.35,-15.67,-15.68,-16.61,-16.62,-15.01,-15.65,-15.53,-14.85,-14.76,-16.08,-17.22,-16.63,-16.05,-16.61,-16.75,-16.41,-12.15,-17.43,-16.94,-15.18,-14.64,-16.70,-15.83,-15.10,-15.26,-15.79,-15.06,-15.71,-16.64,-16.15,-14.03,-15.93
2022-07-24 19:10:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 19: train = -15.6828(7.43m/561) | dev = -15.4687(0.46m/89) 
2022-07-24 19:10:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:10:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.56)...
2022-07-24 19:11:25 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.53)...
2022-07-24 19:12:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.14)...
2022-07-24 19:12:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.53)...
2022-07-24 19:13:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.71)...
2022-07-24 19:14:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.13)...
2022-07-24 19:14:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.58)...
2022-07-24 19:15:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.97)...
2022-07-24 19:16:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.98)...
2022-07-24 19:16:43 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.57)...
2022-07-24 19:17:23 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.72)...
2022-07-24 19:17:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:17:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.32)...
2022-07-24 19:17:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.55,-16.63,-14.57,-15.04,-12.66,-14.92,-14.60,-16.69,-14.06,-15.50,-15.08,-16.18,-17.22,-16.49,-15.46,-15.25,-15.98,-15.71,-15.13,-15.03,-15.62,-15.19,-14.03,-13.72,-17.50,-16.39,-16.81,-15.33,-14.68,-14.70,-15.27,-16.27,-15.67,-13.71,-16.74,-14.85,-16.35,-14.31,-14.96,-15.58,-15.08,-13.91,-14.60,-16.85,-13.82,-16.15,-14.97,-15.87,-14.72,-15.63,-14.46,-15.77,-16.66,-13.26,-16.44,-15.41,-13.39,-15.67,-15.63,-16.55,-16.47,-14.97,-15.44,-15.63,-14.89,-14.75,-16.08,-16.75,-16.63,-16.12,-16.61,-16.75,-16.48,-12.14,-17.36,-16.98,-15.19,-14.52,-16.70,-15.82,-15.00,-15.48,-15.73,-15.41,-15.76,-16.66,-16.30,-14.03,-15.98
2022-07-24 19:17:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 20: train = -15.5890(7.44m/561) | dev = -15.4599(0.46m/89) | no impr, best = -15.4687
2022-07-24 19:18:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:18:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.77)...
2022-07-24 19:19:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.74)...
2022-07-24 19:19:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.79)...
2022-07-24 19:20:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.65)...
2022-07-24 19:21:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.80)...
2022-07-24 19:21:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.71)...
2022-07-24 19:22:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.71)...
2022-07-24 19:23:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.97)...
2022-07-24 19:23:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.19)...
2022-07-24 19:24:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.51)...
2022-07-24 19:25:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.40)...
2022-07-24 19:25:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:25:41 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.25)...
2022-07-24 19:25:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.55,-16.54,-14.47,-15.02,-12.44,-14.75,-14.53,-16.60,-13.91,-15.36,-14.99,-16.04,-17.14,-16.25,-15.28,-15.21,-15.90,-15.66,-15.09,-14.91,-15.59,-15.09,-13.85,-13.59,-17.27,-16.32,-17.26,-15.05,-14.54,-14.45,-15.15,-16.09,-15.93,-13.85,-16.88,-14.85,-16.23,-14.37,-14.82,-15.50,-15.07,-13.68,-14.45,-16.99,-13.74,-16.05,-15.21,-15.79,-14.65,-15.56,-14.33,-15.71,-16.56,-13.16,-16.34,-15.37,-13.31,-15.45,-15.50,-16.47,-16.42,-14.85,-15.45,-15.42,-14.74,-14.55,-15.77,-16.56,-16.48,-16.04,-16.57,-16.62,-16.28,-11.88,-17.21,-16.87,-15.11,-14.45,-16.60,-15.67,-14.98,-15.39,-15.66,-15.21,-15.61,-16.49,-16.15,-13.43,-15.92
2022-07-24 19:25:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 21: train = -15.6589(7.44m/561) | dev = -15.3608(0.45m/89) | no impr, best = -15.4687
2022-07-24 19:25:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:26:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.75)...
2022-07-24 19:27:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.82)...
2022-07-24 19:27:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.91)...
2022-07-24 19:28:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.61)...
2022-07-24 19:29:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.78)...
2022-07-24 19:29:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.58)...
2022-07-24 19:30:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.95)...
2022-07-24 19:31:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.91)...
2022-07-24 19:31:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.67)...
2022-07-24 19:32:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.70)...
2022-07-24 19:33:10 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.82)...
2022-07-24 19:33:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:33:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.46)...
2022-07-24 19:33:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.82,-16.72,-14.73,-14.93,-12.73,-15.02,-14.77,-16.71,-14.22,-15.64,-15.23,-16.31,-17.33,-16.55,-15.59,-15.55,-16.12,-15.86,-15.32,-15.18,-15.79,-15.28,-14.16,-13.88,-17.61,-16.46,-17.38,-15.37,-14.79,-14.78,-15.33,-16.40,-16.00,-13.98,-17.05,-14.94,-16.47,-14.48,-15.08,-15.74,-15.29,-13.97,-14.75,-17.06,-13.95,-16.25,-15.09,-15.95,-14.82,-15.73,-14.62,-15.91,-16.73,-13.52,-16.61,-15.63,-13.55,-15.82,-15.71,-16.70,-16.68,-15.08,-15.61,-15.80,-14.97,-14.78,-16.24,-17.02,-16.74,-16.24,-16.79,-16.91,-16.45,-12.19,-17.48,-17.10,-15.43,-14.63,-16.83,-16.06,-15.19,-15.60,-15.83,-15.40,-15.93,-16.69,-16.34,-14.26,-16.08
2022-07-24 19:33:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 22: train = -15.7683(7.43m/561) | dev = -15.5993(0.46m/89) 
2022-07-24 19:33:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:34:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.93)...
2022-07-24 19:35:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.85)...
2022-07-24 19:35:46 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.76)...
2022-07-24 19:36:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -15.63)...
2022-07-24 19:37:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.91)...
2022-07-24 19:37:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.85)...
2022-07-24 19:38:25 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.98)...
2022-07-24 19:39:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.04)...
2022-07-24 19:39:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.02)...
2022-07-24 19:40:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.71)...
2022-07-24 19:41:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.88)...
2022-07-24 19:41:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:41:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.43)...
2022-07-24 19:41:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.70,-16.68,-14.75,-14.84,-12.52,-15.04,-14.70,-16.73,-14.12,-15.49,-15.16,-16.24,-17.29,-16.46,-15.46,-15.46,-16.05,-15.88,-15.27,-15.15,-15.81,-15.36,-14.07,-14.25,-17.47,-16.47,-17.15,-15.26,-14.75,-14.72,-15.32,-16.30,-16.39,-14.02,-17.01,-14.95,-16.39,-14.31,-15.07,-15.70,-15.40,-13.93,-14.67,-16.99,-13.83,-16.24,-15.05,-15.94,-14.97,-15.62,-14.54,-15.93,-16.71,-13.45,-16.47,-15.63,-13.45,-15.77,-15.57,-16.69,-16.69,-15.15,-15.59,-15.66,-14.89,-14.77,-16.13,-17.08,-16.73,-16.15,-16.80,-16.79,-16.43,-12.20,-17.45,-17.06,-15.21,-14.65,-16.82,-15.85,-15.15,-15.58,-15.83,-15.43,-15.42,-16.72,-16.27,-13.74,-15.91
2022-07-24 19:41:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 23: train = -15.8676(7.43m/561) | dev = -15.5475(0.45m/89) | no impr, best = -15.5993
2022-07-24 19:41:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:42:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.85)...
2022-07-24 19:43:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.96)...
2022-07-24 19:43:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.92)...
2022-07-24 19:44:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.07)...
2022-07-24 19:44:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.80)...
2022-07-24 19:45:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.77)...
2022-07-24 19:46:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.94)...
2022-07-24 19:46:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.73)...
2022-07-24 19:47:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.66)...
2022-07-24 19:48:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.80)...
2022-07-24 19:48:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.72)...
2022-07-24 19:49:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:49:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.37)...
2022-07-24 19:49:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.61,-16.61,-14.59,-14.83,-12.34,-15.09,-14.65,-16.66,-14.12,-15.52,-15.14,-16.26,-17.24,-16.53,-15.51,-15.32,-16.07,-15.82,-15.09,-15.12,-15.73,-15.35,-14.00,-13.94,-17.44,-16.38,-17.22,-15.31,-14.62,-14.67,-15.20,-16.26,-16.24,-13.84,-16.99,-14.91,-16.39,-14.43,-15.00,-15.66,-15.30,-13.85,-14.65,-16.89,-13.84,-16.20,-14.95,-15.95,-14.80,-15.51,-14.52,-15.77,-16.58,-13.27,-16.50,-15.36,-13.46,-15.60,-15.53,-16.61,-16.63,-14.93,-15.64,-15.73,-14.73,-14.73,-16.05,-17.09,-16.68,-16.00,-16.71,-16.79,-16.48,-11.98,-17.42,-17.03,-15.16,-14.52,-16.83,-15.91,-15.05,-15.41,-15.84,-15.42,-15.77,-16.74,-16.18,-14.02,-15.95
2022-07-24 19:49:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 24: train = -15.8446(7.43m/561) | dev = -15.4970(0.46m/89) | no impr, best = -15.5993
2022-07-24 19:49:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:50:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.26)...
2022-07-24 19:50:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -15.88)...
2022-07-24 19:51:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -15.91)...
2022-07-24 19:52:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.06)...
2022-07-24 19:52:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.77)...
2022-07-24 19:53:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.38)...
2022-07-24 19:54:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.28)...
2022-07-24 19:54:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.36)...
2022-07-24 19:55:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.26)...
2022-07-24 19:56:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.11)...
2022-07-24 19:56:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -15.32)...
2022-07-24 19:57:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 19:57:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.26)...
2022-07-24 19:57:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.57,-16.50,-14.44,-14.73,-12.48,-14.82,-14.59,-16.59,-14.02,-15.37,-14.99,-16.09,-17.25,-16.31,-15.36,-15.22,-15.95,-15.70,-15.17,-14.85,-15.62,-15.02,-13.90,-13.97,-17.24,-16.33,-17.22,-15.21,-14.52,-14.53,-15.03,-15.98,-15.85,-13.71,-16.67,-14.78,-16.29,-14.36,-14.85,-15.57,-15.23,-13.68,-14.41,-16.77,-13.75,-16.07,-15.13,-15.78,-14.87,-15.46,-14.30,-15.78,-16.51,-13.10,-16.33,-15.40,-13.29,-15.68,-15.50,-16.37,-16.25,-14.92,-15.50,-15.46,-14.61,-14.65,-15.63,-16.87,-16.44,-15.96,-16.58,-16.66,-16.41,-11.96,-17.28,-16.92,-15.21,-14.36,-16.63,-15.76,-15.04,-15.43,-15.72,-15.29,-15.62,-16.53,-16.13,-13.84,-15.89
2022-07-24 19:57:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=1.000e-03) - Epoch 25: train = -15.7681(7.44m/561) | dev = -15.3774(0.45m/89) | no impr, best = -15.5993
2022-07-24 19:57:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 19:58:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.75)...
2022-07-24 19:58:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.01)...
2022-07-24 19:59:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.06)...
2022-07-24 20:00:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.14)...
2022-07-24 20:00:46 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.76)...
2022-07-24 20:01:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.03)...
2022-07-24 20:02:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.33)...
2022-07-24 20:02:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.02)...
2022-07-24 20:03:25 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.95)...
2022-07-24 20:04:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.16)...
2022-07-24 20:04:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.13)...
2022-07-24 20:04:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 20:05:09 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.60)...
2022-07-24 20:05:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.81,-16.86,-14.80,-15.07,-12.82,-15.18,-14.90,-16.94,-14.32,-15.72,-15.30,-16.44,-17.53,-16.70,-15.69,-15.65,-16.21,-15.97,-15.55,-15.33,-15.89,-15.51,-14.29,-14.36,-17.67,-16.62,-17.62,-15.41,-14.89,-14.94,-15.47,-16.47,-16.19,-14.18,-17.14,-15.11,-16.53,-14.66,-15.21,-15.84,-15.54,-14.25,-14.66,-17.32,-14.07,-16.38,-15.25,-16.05,-14.89,-15.84,-14.71,-16.00,-16.83,-13.47,-16.72,-15.69,-13.48,-15.97,-15.84,-16.81,-16.80,-15.27,-15.72,-15.89,-15.05,-14.94,-16.33,-17.09,-16.76,-16.37,-16.98,-17.02,-16.66,-12.35,-17.58,-17.26,-15.57,-14.83,-16.89,-16.12,-15.36,-15.65,-15.93,-15.50,-15.96,-16.82,-16.50,-14.25,-16.15
2022-07-24 20:05:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 26: train = -16.0387(7.43m/561) | dev = -15.7210(0.46m/89) 
2022-07-24 20:05:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 20:06:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.41)...
2022-07-24 20:06:41 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.18)...
2022-07-24 20:07:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.18)...
2022-07-24 20:08:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.11)...
2022-07-24 20:08:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -15.94)...
2022-07-24 20:09:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.87)...
2022-07-24 20:09:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.28)...
2022-07-24 20:10:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.10)...
2022-07-24 20:11:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.33)...
2022-07-24 20:11:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.39)...
2022-07-24 20:12:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.13)...
2022-07-24 20:12:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 20:13:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.66)...
2022-07-24 20:13:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.90,-16.92,-14.88,-15.23,-12.87,-15.15,-14.91,-16.96,-14.43,-15.74,-15.40,-16.44,-17.54,-16.80,-15.71,-15.64,-16.27,-16.02,-15.51,-15.37,-16.05,-15.59,-14.34,-14.38,-17.72,-16.60,-17.64,-15.45,-14.95,-15.03,-15.53,-16.52,-16.31,-14.16,-17.16,-15.17,-16.63,-14.66,-15.20,-15.96,-15.60,-14.36,-14.90,-17.37,-14.12,-16.46,-15.29,-16.12,-15.16,-15.88,-14.72,-16.08,-16.86,-13.50,-16.81,-15.79,-13.59,-16.08,-15.84,-16.88,-16.85,-15.34,-15.80,-15.96,-15.15,-14.97,-16.33,-17.28,-16.77,-16.38,-17.05,-17.11,-16.70,-12.52,-17.61,-17.33,-15.74,-14.83,-17.00,-16.11,-15.40,-15.74,-16.03,-15.61,-16.02,-16.88,-16.54,-14.15,-16.23
2022-07-24 20:13:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 27: train = -16.1932(7.43m/561) | dev = -15.7817(0.46m/89) 
2022-07-24 20:13:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 20:13:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.33)...
2022-07-24 20:14:34 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.38)...
2022-07-24 20:15:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.20)...
2022-07-24 20:15:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.28)...
2022-07-24 20:16:34 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.38)...
2022-07-24 20:17:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.14)...
2022-07-24 20:17:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.10)...
2022-07-24 20:18:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.19)...
2022-07-24 20:19:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.08)...
2022-07-24 20:19:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.35)...
2022-07-24 20:20:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.45)...
2022-07-24 20:20:41 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 20:20:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.63)...
2022-07-24 20:21:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.95,-16.89,-14.86,-15.03,-12.88,-15.17,-14.96,-16.90,-14.38,-15.74,-15.40,-16.44,-17.55,-16.77,-15.68,-15.65,-16.30,-15.98,-15.50,-15.32,-16.01,-15.53,-14.33,-14.36,-17.76,-16.64,-17.43,-15.45,-14.90,-15.01,-15.39,-16.52,-16.40,-14.14,-16.87,-15.14,-16.60,-14.62,-15.20,-15.96,-15.55,-14.35,-14.85,-17.31,-14.10,-16.44,-15.21,-16.14,-15.10,-15.84,-14.78,-16.09,-16.87,-13.48,-16.86,-15.81,-13.48,-16.06,-15.81,-16.90,-16.80,-15.31,-15.78,-16.02,-15.16,-14.99,-16.32,-17.28,-16.86,-16.36,-17.06,-17.06,-16.69,-12.43,-17.56,-17.26,-15.71,-14.83,-16.94,-16.19,-15.39,-15.70,-16.02,-15.62,-16.05,-16.86,-16.52,-14.36,-16.23
2022-07-24 20:21:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 28: train = -16.2597(7.43m/561) | dev = -15.7637(0.45m/89) | no impr, best = -15.7817
2022-07-24 20:21:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 20:21:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.82)...
2022-07-24 20:22:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.22)...
2022-07-24 20:23:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.35)...
2022-07-24 20:23:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.43)...
2022-07-24 20:24:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.41)...
2022-07-24 20:25:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.43)...
2022-07-24 20:25:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.18)...
2022-07-24 20:26:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -15.44)...
2022-07-24 20:27:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -15.94)...
2022-07-24 20:27:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -15.87)...
2022-07-24 20:28:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.40)...
2022-07-24 20:28:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 20:28:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.58)...
2022-07-24 20:29:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.89,-16.90,-14.75,-15.04,-12.85,-15.12,-14.89,-16.88,-14.31,-15.68,-15.30,-16.42,-17.50,-16.76,-15.65,-15.65,-16.26,-16.01,-15.45,-15.30,-15.96,-15.47,-14.27,-14.20,-17.72,-16.49,-17.61,-15.35,-14.91,-14.94,-15.40,-16.38,-16.25,-14.14,-17.11,-15.05,-16.55,-14.50,-15.28,-15.87,-15.41,-13.98,-14.84,-17.15,-14.05,-16.40,-15.16,-16.09,-14.97,-15.75,-14.70,-16.00,-16.81,-13.43,-16.81,-15.66,-13.54,-16.01,-15.79,-16.74,-16.77,-15.21,-15.72,-15.96,-15.04,-14.92,-16.23,-17.29,-16.83,-16.29,-17.01,-17.04,-16.67,-12.26,-17.59,-17.28,-15.47,-14.70,-16.86,-16.11,-15.32,-15.67,-16.03,-15.59,-15.95,-16.81,-16.45,-14.25,-16.14
2022-07-24 20:29:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 29: train = -16.1329(7.46m/561) | dev = -15.7057(0.45m/89) | no impr, best = -15.7817
2022-07-24 20:29:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 20:29:43 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.24)...
2022-07-24 20:30:25 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.31)...
2022-07-24 20:31:09 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.12)...
2022-07-24 20:31:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.29)...
2022-07-24 20:32:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.26)...
2022-07-24 20:33:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.13)...
2022-07-24 20:33:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.36)...
2022-07-24 20:34:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.43)...
2022-07-24 20:35:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.37)...
2022-07-24 20:35:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.31)...
2022-07-24 20:36:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.18)...
2022-07-24 20:36:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 20:36:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.66)...
2022-07-24 20:37:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.94,-16.99,-14.87,-15.08,-12.90,-15.21,-14.93,-16.97,-14.41,-15.79,-15.36,-16.49,-17.56,-16.78,-15.77,-15.68,-16.28,-16.05,-15.53,-15.39,-16.04,-15.39,-14.24,-14.36,-17.75,-16.52,-17.57,-15.44,-14.92,-15.01,-15.57,-16.56,-16.40,-14.28,-17.21,-15.18,-16.63,-14.50,-15.22,-15.91,-15.64,-14.22,-15.04,-17.20,-14.12,-16.45,-15.35,-16.12,-15.09,-15.87,-14.65,-16.03,-16.89,-13.51,-16.83,-15.72,-13.66,-16.10,-15.86,-16.89,-16.86,-15.31,-15.81,-15.94,-15.15,-15.00,-16.32,-17.38,-16.86,-16.33,-17.03,-17.12,-16.72,-12.37,-17.61,-17.26,-15.43,-14.81,-16.98,-16.15,-15.42,-15.72,-15.97,-15.63,-16.18,-16.88,-16.60,-14.52,-16.20
2022-07-24 20:37:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 30: train = -16.2723(7.61m/561) | dev = -15.7807(0.46m/89) | no impr, best = -15.7817
2022-07-24 20:37:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 20:37:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.34)...
2022-07-24 20:38:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.25)...
2022-07-24 20:39:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.24)...
2022-07-24 20:39:46 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.54)...
2022-07-24 20:40:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.49)...
2022-07-24 20:41:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -15.70)...
2022-07-24 20:41:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -15.96)...
2022-07-24 20:42:25 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.59)...
2022-07-24 20:43:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.11)...
2022-07-24 20:43:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.55)...
2022-07-24 20:44:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.08)...
2022-07-24 20:44:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 20:44:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.65)...
2022-07-24 20:45:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.88,-16.88,-14.90,-15.17,-12.86,-15.19,-14.93,-16.97,-14.42,-15.78,-15.38,-16.47,-17.55,-16.85,-15.71,-15.66,-16.35,-16.09,-15.48,-15.43,-15.97,-15.53,-14.31,-14.52,-17.73,-16.47,-17.60,-15.39,-14.94,-15.02,-15.53,-16.47,-16.41,-14.26,-17.18,-15.09,-16.61,-14.57,-15.25,-15.89,-15.60,-14.27,-15.20,-17.24,-14.13,-16.46,-15.33,-16.16,-15.02,-15.63,-14.71,-16.12,-16.92,-13.50,-16.78,-15.81,-13.67,-16.08,-15.79,-16.83,-16.83,-15.35,-15.79,-16.08,-15.10,-14.98,-16.26,-17.39,-16.95,-16.41,-17.05,-17.10,-16.75,-12.41,-17.61,-17.32,-15.35,-14.82,-16.98,-16.16,-15.36,-15.68,-16.01,-15.66,-16.00,-16.88,-16.61,-14.42,-16.19
2022-07-24 20:45:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 31: train = -16.2518(7.43m/561) | dev = -15.7805(0.45m/89) | no impr, best = -15.7807
2022-07-24 20:45:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 20:45:41 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.23)...
2022-07-24 20:46:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.58)...
2022-07-24 20:47:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.44)...
2022-07-24 20:47:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.44)...
2022-07-24 20:48:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.20)...
2022-07-24 20:48:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.59)...
2022-07-24 20:49:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.12)...
2022-07-24 20:50:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.38)...
2022-07-24 20:50:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.40)...
2022-07-24 20:51:38 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.30)...
2022-07-24 20:52:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.45)...
2022-07-24 20:52:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 20:52:43 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.69)...
2022-07-24 20:52:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -15.02,-16.98,-14.91,-15.11,-12.96,-15.23,-14.97,-16.91,-14.42,-15.86,-15.40,-16.48,-17.53,-16.82,-15.78,-15.73,-16.39,-16.09,-15.55,-15.42,-16.03,-15.59,-14.35,-14.51,-17.75,-16.62,-17.66,-15.43,-15.02,-15.03,-15.56,-16.57,-16.28,-14.25,-17.16,-15.22,-16.64,-14.68,-15.28,-15.96,-15.55,-14.35,-15.15,-17.13,-14.12,-16.48,-15.41,-16.15,-15.06,-15.85,-14.83,-16.16,-16.85,-13.54,-16.82,-15.84,-13.75,-16.15,-15.80,-16.92,-16.91,-15.32,-15.88,-16.08,-15.13,-15.03,-16.43,-17.43,-16.98,-16.34,-17.09,-17.14,-16.78,-12.43,-17.61,-17.33,-15.49,-14.87,-17.05,-16.18,-15.44,-15.70,-16.09,-15.68,-16.22,-16.90,-16.59,-14.14,-16.22
2022-07-24 20:52:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 32: train = -16.3792(7.44m/561) | dev = -15.8146(0.46m/89) 
2022-07-24 20:52:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 20:53:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.34)...
2022-07-24 20:54:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.53)...
2022-07-24 20:54:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.60)...
2022-07-24 20:55:34 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.24)...
2022-07-24 20:56:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.28)...
2022-07-24 20:56:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.43)...
2022-07-24 20:57:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.31)...
2022-07-24 20:58:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.40)...
2022-07-24 20:58:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.44)...
2022-07-24 20:59:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.38)...
2022-07-24 21:00:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.66)...
2022-07-24 21:00:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:00:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.68)...
2022-07-24 21:00:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -15.03,-16.98,-14.91,-15.11,-12.96,-15.19,-14.97,-16.93,-14.46,-15.83,-15.43,-16.50,-17.55,-16.84,-15.81,-15.69,-16.37,-16.10,-15.29,-15.49,-16.06,-15.66,-14.24,-14.45,-17.84,-16.59,-17.68,-15.38,-14.97,-15.08,-15.60,-16.67,-16.56,-14.23,-17.20,-15.24,-16.66,-14.61,-15.31,-15.99,-15.62,-14.27,-15.17,-17.24,-14.12,-16.51,-15.42,-16.18,-15.02,-15.18,-14.82,-16.17,-16.91,-13.57,-16.88,-15.88,-13.62,-16.14,-15.84,-16.93,-16.85,-15.38,-15.88,-16.11,-15.24,-15.07,-16.48,-17.53,-16.96,-16.42,-17.12,-17.17,-16.80,-12.44,-17.65,-17.29,-15.41,-14.91,-17.03,-16.22,-15.44,-15.74,-16.05,-15.66,-16.27,-16.91,-16.60,-14.18,-16.26
2022-07-24 21:00:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 33: train = -16.4221(7.43m/561) | dev = -15.8204(0.46m/89) 
2022-07-24 21:00:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:01:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.27)...
2022-07-24 21:02:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.51)...
2022-07-24 21:02:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.16)...
2022-07-24 21:03:28 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.53)...
2022-07-24 21:04:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.34)...
2022-07-24 21:04:47 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.53)...
2022-07-24 21:05:27 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.38)...
2022-07-24 21:06:07 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.71)...
2022-07-24 21:06:46 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.28)...
2022-07-24 21:07:26 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.80)...
2022-07-24 21:08:06 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.34)...
2022-07-24 21:08:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:08:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.65)...
2022-07-24 21:08:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -15.00,-16.98,-14.87,-15.02,-12.97,-15.15,-14.98,-16.94,-14.46,-15.76,-15.43,-16.42,-17.54,-16.81,-15.81,-15.67,-16.38,-16.07,-15.37,-15.43,-15.91,-15.55,-14.27,-13.97,-17.75,-16.56,-17.63,-15.41,-14.97,-15.04,-15.56,-16.62,-16.29,-14.18,-17.15,-15.24,-16.65,-14.52,-15.26,-15.96,-15.59,-14.33,-15.22,-17.17,-14.07,-16.49,-15.20,-16.16,-15.01,-15.82,-14.82,-16.10,-16.82,-13.62,-16.84,-15.79,-13.61,-16.07,-15.75,-16.88,-16.91,-15.32,-15.87,-16.12,-15.18,-15.00,-16.40,-17.44,-16.98,-16.36,-17.10,-17.09,-16.81,-12.40,-17.61,-17.34,-15.33,-14.82,-17.04,-16.29,-15.44,-15.73,-16.07,-15.71,-16.24,-16.89,-16.51,-14.20,-16.22
2022-07-24 21:08:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 34: train = -16.4410(7.43m/561) | dev = -15.7907(0.45m/89) | no impr, best = -15.8204
2022-07-24 21:08:42 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:09:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.57)...
2022-07-24 21:10:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.48)...
2022-07-24 21:10:41 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.52)...
2022-07-24 21:11:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.40)...
2022-07-24 21:12:01 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.43)...
2022-07-24 21:12:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.51)...
2022-07-24 21:13:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.29)...
2022-07-24 21:14:00 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.51)...
2022-07-24 21:14:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.61)...
2022-07-24 21:15:19 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.34)...
2022-07-24 21:15:59 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.65)...
2022-07-24 21:16:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:16:23 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.70)...
2022-07-24 21:16:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.95,-16.96,-14.88,-15.18,-12.89,-15.15,-15.07,-17.00,-14.47,-15.82,-15.39,-16.50,-17.67,-16.87,-15.80,-15.62,-16.39,-16.11,-15.58,-15.40,-16.00,-15.68,-14.28,-14.43,-17.83,-16.67,-17.68,-15.37,-14.96,-15.06,-15.55,-16.59,-16.51,-14.21,-17.16,-15.25,-16.62,-14.67,-15.25,-15.98,-15.66,-14.33,-15.21,-17.25,-14.12,-16.48,-15.27,-16.21,-14.99,-15.91,-14.81,-16.15,-16.97,-13.46,-16.89,-15.82,-13.57,-16.17,-15.90,-16.92,-16.84,-15.40,-15.79,-16.00,-15.22,-15.07,-16.32,-17.50,-16.99,-16.42,-17.10,-17.15,-16.75,-12.51,-17.65,-17.39,-15.39,-14.87,-17.01,-16.15,-15.46,-15.72,-16.05,-15.67,-16.13,-16.93,-16.61,-14.40,-16.26
2022-07-24 21:16:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 35: train = -16.4842(7.43m/561) | dev = -15.8238(0.46m/89) 
2022-07-24 21:16:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:17:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.45)...
2022-07-24 21:17:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.63)...
2022-07-24 21:18:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.33)...
2022-07-24 21:19:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.45)...
2022-07-24 21:19:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.38)...
2022-07-24 21:20:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.48)...
2022-07-24 21:21:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.48)...
2022-07-24 21:21:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.38)...
2022-07-24 21:22:35 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.69)...
2022-07-24 21:23:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.23)...
2022-07-24 21:23:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.24)...
2022-07-24 21:24:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:24:20 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.68)...
2022-07-24 21:24:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.97,-16.95,-14.86,-15.18,-12.86,-15.17,-14.90,-16.96,-14.34,-15.80,-15.41,-16.45,-17.60,-16.79,-15.76,-15.71,-16.36,-16.05,-15.54,-15.36,-16.04,-15.66,-14.21,-14.26,-17.78,-16.66,-17.72,-15.39,-14.98,-14.96,-15.55,-16.66,-16.63,-14.26,-17.15,-15.14,-16.67,-14.65,-15.25,-15.99,-15.63,-14.15,-15.35,-17.28,-14.15,-16.46,-15.28,-16.11,-14.99,-15.92,-14.77,-16.13,-16.94,-13.50,-16.74,-15.85,-13.60,-16.10,-15.85,-16.90,-16.89,-15.24,-15.77,-15.99,-15.26,-15.00,-16.36,-17.44,-16.92,-16.36,-17.13,-17.15,-16.76,-12.44,-17.59,-17.42,-15.44,-14.82,-16.92,-16.18,-15.50,-15.67,-16.01,-15.61,-16.18,-16.90,-16.55,-14.38,-16.21
2022-07-24 21:24:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 36: train = -16.4363(7.47m/561) | dev = -15.8025(0.45m/89) | no impr, best = -15.8238
2022-07-24 21:24:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:25:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.18)...
2022-07-24 21:25:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.33)...
2022-07-24 21:26:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.39)...
2022-07-24 21:27:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.43)...
2022-07-24 21:27:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.57)...
2022-07-24 21:28:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.70)...
2022-07-24 21:29:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.56)...
2022-07-24 21:29:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.57)...
2022-07-24 21:30:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.60)...
2022-07-24 21:31:14 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.55)...
2022-07-24 21:31:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.58)...
2022-07-24 21:32:02 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:32:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.66)...
2022-07-24 21:32:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.97,-16.92,-14.81,-15.16,-12.89,-15.20,-14.99,-16.99,-14.44,-15.83,-15.39,-16.43,-17.58,-16.81,-15.73,-15.66,-16.30,-16.04,-15.24,-15.37,-16.01,-15.63,-14.28,-14.39,-17.77,-16.64,-17.69,-15.38,-14.95,-15.00,-15.56,-16.58,-16.30,-14.08,-17.12,-15.21,-16.61,-14.63,-15.21,-15.94,-15.61,-14.29,-14.96,-17.23,-14.07,-16.45,-15.38,-16.21,-15.13,-15.83,-14.84,-16.10,-16.81,-13.54,-16.82,-15.81,-13.58,-16.14,-15.71,-16.97,-16.89,-15.30,-15.89,-16.05,-15.09,-15.05,-16.30,-17.42,-16.95,-16.31,-16.97,-17.07,-16.75,-12.51,-17.64,-17.33,-15.41,-14.84,-17.02,-16.18,-15.38,-15.73,-16.02,-15.53,-16.21,-16.92,-16.53,-14.28,-16.12
2022-07-24 21:32:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 37: train = -16.4963(7.51m/561) | dev = -15.7854(0.47m/89) | no impr, best = -15.8238
2022-07-24 21:32:30 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:33:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.66)...
2022-07-24 21:33:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.56)...
2022-07-24 21:34:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.52)...
2022-07-24 21:35:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.62)...
2022-07-24 21:35:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.21)...
2022-07-24 21:36:34 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.76)...
2022-07-24 21:37:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.48)...
2022-07-24 21:37:56 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.65)...
2022-07-24 21:38:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.66)...
2022-07-24 21:39:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.31)...
2022-07-24 21:39:57 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.47)...
2022-07-24 21:40:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:40:21 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.60)...
2022-07-24 21:40:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -14.92,-16.73,-14.86,-15.07,-12.87,-15.11,-14.91,-16.87,-14.33,-15.73,-15.32,-16.39,-17.55,-16.78,-15.68,-15.61,-16.30,-16.08,-15.17,-15.30,-15.97,-15.51,-14.29,-14.06,-17.75,-16.54,-17.66,-15.29,-14.82,-14.96,-15.48,-16.56,-16.39,-14.18,-17.11,-15.06,-16.60,-14.53,-15.18,-15.86,-15.64,-14.18,-15.22,-17.16,-14.06,-16.40,-15.19,-16.16,-14.76,-15.72,-14.63,-16.06,-16.85,-13.38,-16.70,-15.82,-13.43,-15.97,-15.76,-16.79,-16.78,-15.33,-15.70,-15.98,-15.15,-15.01,-16.19,-17.36,-16.86,-16.30,-16.98,-17.07,-16.73,-12.36,-17.56,-17.29,-15.58,-14.87,-17.01,-16.06,-15.28,-15.67,-16.09,-15.36,-16.07,-16.86,-16.47,-14.35,-16.14
2022-07-24 21:40:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=5.000e-04) - Epoch 38: train = -16.5364(7.59m/561) | dev = -15.7268(0.46m/89) | no impr, best = -15.8238
2022-07-24 21:40:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:41:13 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.49)...
2022-07-24 21:41:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.56)...
2022-07-24 21:42:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.58)...
2022-07-24 21:43:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.64)...
2022-07-24 21:43:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.85)...
2022-07-24 21:44:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.74)...
2022-07-24 21:45:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -17.02)...
2022-07-24 21:45:53 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.65)...
2022-07-24 21:46:33 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.45)...
2022-07-24 21:47:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.78)...
2022-07-24 21:48:05 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.60)...
2022-07-24 21:48:15 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:48:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.72)...
2022-07-24 21:48:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -15.10,-17.01,-14.90,-15.25,-12.97,-15.22,-15.05,-17.03,-14.46,-15.87,-15.47,-16.52,-17.64,-16.94,-15.90,-15.76,-16.43,-16.17,-15.06,-15.42,-16.12,-15.71,-14.36,-14.22,-17.89,-16.72,-17.79,-15.43,-15.02,-15.09,-15.63,-16.73,-16.25,-14.27,-17.20,-15.26,-16.76,-14.65,-15.33,-16.03,-15.63,-14.25,-15.40,-17.20,-14.17,-16.55,-15.39,-16.24,-15.10,-15.66,-14.85,-16.20,-16.92,-13.56,-16.87,-15.90,-13.64,-16.23,-15.91,-17.00,-16.96,-15.37,-15.89,-16.12,-15.16,-15.08,-16.40,-17.56,-17.03,-16.50,-17.16,-17.25,-16.83,-12.48,-17.69,-17.48,-15.47,-14.96,-17.11,-16.28,-15.52,-15.83,-16.07,-15.65,-16.25,-17.00,-16.58,-14.20,-16.29
2022-07-24 21:48:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=2.500e-04) - Epoch 39: train = -16.6651(7.70m/561) | dev = -15.8586(0.61m/89) 
2022-07-24 21:48:52 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:49:39 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.84)...
2022-07-24 21:50:25 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.71)...
2022-07-24 21:51:12 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.75)...
2022-07-24 21:51:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.56)...
2022-07-24 21:52:45 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.51)...
2022-07-24 21:53:32 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.65)...
2022-07-24 21:54:18 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -16.79)...
2022-07-24 21:55:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.82)...
2022-07-24 21:55:51 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.95)...
2022-07-24 21:56:37 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.60)...
2022-07-24 21:57:24 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.83)...
2022-07-24 21:57:34 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 21:57:55 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.71)...
2022-07-24 21:58:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -15.05,-17.01,-14.89,-15.18,-12.95,-15.19,-15.00,-16.98,-14.44,-15.87,-15.47,-16.49,-17.63,-16.90,-15.88,-15.74,-16.40,-16.12,-15.05,-15.48,-16.11,-15.73,-14.37,-14.25,-17.84,-16.72,-17.80,-15.44,-15.04,-15.09,-15.64,-16.70,-16.37,-14.26,-17.17,-15.23,-16.73,-14.61,-15.31,-15.98,-15.66,-14.19,-15.42,-17.20,-14.16,-16.56,-15.24,-16.25,-15.11,-15.61,-14.86,-16.23,-16.92,-13.49,-16.88,-15.93,-13.59,-16.20,-15.88,-16.96,-16.96,-15.35,-15.88,-16.18,-15.23,-15.06,-16.40,-17.57,-17.05,-16.39,-17.14,-17.20,-16.81,-12.50,-17.68,-17.45,-15.45,-14.93,-17.04,-16.29,-15.52,-15.86,-16.12,-15.66,-16.28,-16.99,-16.57,-14.19,-16.32
2022-07-24 21:58:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=2.500e-04) - Epoch 40: train = -16.7226(8.69m/561) | dev = -15.8487(0.61m/89) | no impr, best = -15.8586
2022-07-24 21:58:11 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
2022-07-24 21:58:58 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -16.57)...
2022-07-24 21:59:44 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 100 batches(loss = -16.38)...
2022-07-24 22:00:31 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 150 batches(loss = -16.67)...
2022-07-24 22:01:17 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 200 batches(loss = -16.84)...
2022-07-24 22:02:03 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 250 batches(loss = -16.71)...
2022-07-24 22:02:49 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 300 batches(loss = -16.92)...
2022-07-24 22:03:36 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 350 batches(loss = -17.04)...
2022-07-24 22:04:22 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 400 batches(loss = -16.72)...
2022-07-24 22:05:08 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 450 batches(loss = -16.84)...
2022-07-24 22:05:54 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 500 batches(loss = -16.87)...
2022-07-24 22:06:40 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 550 batches(loss = -16.74)...
2022-07-24 22:06:48 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:201 - INFO ] Set eval mode...
2022-07-24 22:07:04 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:67 - INFO ] Processed 50 batches(loss = -15.74)...
2022-07-24 22:07:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:74 - INFO ] Loss on 89 batches: -15.14,-16.94,-14.93,-15.23,-12.92,-15.19,-14.99,-17.03,-14.43,-15.93,-15.46,-16.53,-17.61,-16.90,-15.91,-15.76,-16.42,-16.17,-15.55,-15.40,-16.14,-15.69,-14.32,-14.24,-17.84,-16.71,-17.78,-15.44,-14.99,-15.10,-15.64,-16.68,-16.57,-14.25,-17.16,-15.26,-16.75,-14.66,-15.30,-16.03,-15.69,-14.25,-15.46,-17.23,-14.22,-16.57,-15.42,-16.24,-15.22,-15.90,-14.85,-16.20,-16.88,-13.50,-16.86,-15.90,-13.64,-16.21,-15.88,-16.98,-16.91,-15.39,-15.88,-16.11,-15.22,-15.03,-16.37,-17.52,-17.02,-16.45,-17.18,-17.22,-16.81,-12.51,-17.72,-17.43,-15.35,-14.97,-17.02,-16.27,-15.52,-15.82,-16.03,-15.63,-16.29,-17.02,-16.61,-14.36,-16.25
2022-07-24 22:07:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:246 - INFO ] Loss(time/N, lr=2.500e-04) - Epoch 41: train = -16.7475(8.62m/561) | dev = -15.8649(0.46m/89) 
2022-07-24 22:07:16 [/root/mxy/HolidayWork_gruc/nnet/libs/trainer.py:182 - INFO ] Set train mode...
